{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Birthplace (fødested) cleaning\n",
    "Here I inted to clean the birthplace (fødested) field in the data. Notice that the pre-processing scripts are in city_unification (conversion to UTF8, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries for data management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Importing libraries for system management\n",
    "import os\n",
    "\n",
    "#Distance computation\n",
    "from pyjarowinkler import distance\n",
    "#import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Worning directories\n",
    "in_folder  = '/data/import/nirama/utf8/'\n",
    "out_folder = '/home/roregu/workspace/out/'\n",
    "data_folder = '/home/roregu/workspace/data/'\n",
    "\n",
    "#Column to process\n",
    "focus_column = 'fødested'\n",
    "\n",
    "#The Jaro threshold\n",
    "THRESHOLD = 0.9\n",
    "\n",
    "#Number of cores (machine = 28)\n",
    "n_cores = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading DigDag\n",
    "and expanding with variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function adds extra rows in the dataframe *dd* for the \n",
    "# places where *word* exists and replaces it with *replacement*\n",
    "def adding_extra_rows(dd, word, replacement):\n",
    "    dd['special'] = dd['simplename'].apply(lambda x: word in x) \n",
    "    dd['simplename2'] = dd.simplename.apply(lambda x: x.replace(word,replacement))\n",
    "    return pd.concat([dd[['navn', 'enhedid', 'enhedtype', 'art', 'simplename']],dd[dd['special']][['navn', 'enhedid', 'enhedtype', 'art', 'simplename2']].rename(columns={'simplename2':'simplename'})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>navn</th>\n",
       "      <th>enhedid</th>\n",
       "      <th>enhedtype</th>\n",
       "      <th>art</th>\n",
       "      <th>simplename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Kronborg Amt</td>\n",
       "      <td>118765</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>kronborg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Præstø Amt</td>\n",
       "      <td>118791</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>præstø</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Bornholms Amt</td>\n",
       "      <td>118792</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>bornholms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Svendborg Amt</td>\n",
       "      <td>118813</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>svendborg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Ålborg Amt</td>\n",
       "      <td>118819</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>ålborg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Sorø Amt</td>\n",
       "      <td>118785</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>sorø</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Århus Amt</td>\n",
       "      <td>118846</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>århus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Hjørring Amt</td>\n",
       "      <td>118820</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>hjørring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Bøvling Amt</td>\n",
       "      <td>118851</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>bøvling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Vejle Amt</td>\n",
       "      <td>118849</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>vejle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Dueholm Amt</td>\n",
       "      <td>118821</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>dueholm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Ørum Amt</td>\n",
       "      <td>118824</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>ørum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Thisted Amt</td>\n",
       "      <td>118826</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>thisted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Viborg Amt</td>\n",
       "      <td>118830</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>viborg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Ringkøbing Amt</td>\n",
       "      <td>118853</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>ringkøbing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Københavns Kommune</td>\n",
       "      <td>370923</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>københavns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Frederiksberg Kommune</td>\n",
       "      <td>370924</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>frederiksberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Fyns Amt</td>\n",
       "      <td>118739</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>fyns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Sæbygård Amt</td>\n",
       "      <td>118773</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>sæbygård</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Ribe Amt</td>\n",
       "      <td>118855</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>ribe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     navn enhedid enhedtype  art     simplename\n",
       "0            Kronborg Amt  118765        11  amt       kronborg\n",
       "1              Præstø Amt  118791        11  amt         præstø\n",
       "2           Bornholms Amt  118792        11  amt      bornholms\n",
       "3           Svendborg Amt  118813        11  amt      svendborg\n",
       "4              Ålborg Amt  118819        11  amt         ålborg\n",
       "5                Sorø Amt  118785        11  amt           sorø\n",
       "6               Århus Amt  118846        11  amt          århus\n",
       "7            Hjørring Amt  118820        11  amt       hjørring\n",
       "8             Bøvling Amt  118851        11  amt        bøvling\n",
       "9               Vejle Amt  118849        11  amt          vejle\n",
       "10            Dueholm Amt  118821        11  amt        dueholm\n",
       "11               Ørum Amt  118824        11  amt           ørum\n",
       "12            Thisted Amt  118826        11  amt        thisted\n",
       "13             Viborg Amt  118830        11  amt         viborg\n",
       "14         Ringkøbing Amt  118853        11  amt     ringkøbing\n",
       "15     Københavns Kommune  370923        11  amt     københavns\n",
       "16  Frederiksberg Kommune  370924        11  amt  frederiksberg\n",
       "17               Fyns Amt  118739        11  amt           fyns\n",
       "18           Sæbygård Amt  118773        11  amt       sæbygård\n",
       "19               Ribe Amt  118855        11  amt           ribe"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The digdag seems to have duplicates which I do not understand why\n",
    "dd = pd.read_csv(data_folder+'rl_places_digdag_v1.txt', sep = '\\t', encoding='utf-16', dtype=str)\n",
    "dd_org = dd.copy()\n",
    "\n",
    "#Getting the Købstad and putting it to the original data\n",
    "dd2 = pd.read_csv(data_folder+'koebstad.csv', sep = ';', encoding='utf-8', dtype=str)\n",
    "dd2['enhedtype'] = '80'#dd2['art'] \n",
    "dd = pd.concat([dd, dd2[~dd2.isna()][['navn','enhedid','enhedtype','art','simplename']]])\n",
    "dd['simplename'] = dd['simplename'].astype(str)\n",
    "del dd2\n",
    "\n",
    "#Moving the Købstad to the right column\n",
    "dd['art'] = np.where(dd['enhedtype'] == 'Købstad', ['Købstadskommune']*len(dd), dd['art'])\n",
    "\n",
    "#adding a conversion of special characters to latin letters (å -> aa, ø -> oe, æ -> ae) and adding them to the reference list\n",
    "dd = adding_extra_rows(dd, 'å', 'aa')\n",
    "dd = adding_extra_rows(dd, 'ø', 'oe')\n",
    "dd = adding_extra_rows(dd, 'æ', 'ae')\n",
    "\n",
    "#Preparing the names to append them at the simple name\n",
    "dd['art'] = dd['art'].apply({'Amt':'amt', 'Sogn':'sogn','Købstadskommune':'købstad', 'Geografisk Herred':'herred', 'Processing':''}.get)\n",
    "\n",
    "#Adding a duplicated list of their unit type to increase matches\n",
    "dd['simplename2'] = dd.apply(lambda row: str(row['simplename'])+' '+str(row['art']), axis=1)\n",
    "dd = pd.concat([dd[['navn', 'enhedid', 'enhedtype', 'art', 'simplename']],dd[['navn', 'enhedid', 'enhedtype', 'art', 'simplename2']].rename(columns={'simplename2':'simplename'})])\n",
    "\n",
    "#Adding the plural købstæder as well\n",
    "dd = adding_extra_rows(dd, 'købstad', 'købstæder')\n",
    "\n",
    "#Adding spaces instead of hyphens (new rows)\n",
    "dd = adding_extra_rows(dd, '-', ' ')\n",
    "\n",
    "#Removing spaces (new rows)\n",
    "dd = adding_extra_rows(dd, ' ', '')\n",
    "\n",
    "#Adding bysogn and landsogn (new rows)\n",
    "dd = adding_extra_rows(dd, 'sogn', 'bysogn')\n",
    "dd = adding_extra_rows(dd, 'sogn', 'landsogn')\n",
    "\n",
    "#adding rows where the last letter's \"e\" will be removed\n",
    "dd['special'] = dd['simplename'].str[-1] == 'e'\n",
    "dd['simplename2'] = dd['simplename'].str[:-1]\n",
    "dd = pd.concat([dd[['navn', 'enhedid', 'enhedtype', 'art', 'simplename']],dd[dd['special']][['navn', 'enhedid', 'enhedtype', 'art', 'simplename2']].rename(columns={'simplename2':'simplename'})])\n",
    "\n",
    "#Dropping duplicates from digdag\n",
    "#print(dd[dd.duplicated('simplename', keep=False)].sort_values('simplename').head(30))\n",
    "dd.drop_duplicates(['art','simplename'], keep='first', inplace=True)\n",
    "\n",
    "#Drop 'Non' from the list, this may be one of my artifacts...\n",
    "dd = dd[(dd.simplename.apply(lambda x: not 'Non' in x))]\n",
    "\n",
    "#Adding sweeden into the equation\n",
    "dd = dd.append({'navn':'Sweden','enhedid':400000,'enhedtype':'90','art':'country','simplename':'sverige'}, ignore_index=True).append({'navn':'Sweden','enhedid':400000,'enhedtype':'90','art':'country','simplename':'sverrig'}, ignore_index=True)\n",
    "\n",
    "# TODO take into consideration that the same city name can be in varios geographical areas...\n",
    "# It should be matched with herred to increase accuracy for each record. However, right now we're only cleaning\n",
    "# not sure how pressing the issue is...\n",
    "nr_sogn = len(dd_org[dd_org.art=='Sogn'].simplename.unique()) \n",
    "dd.head(20)\n",
    "\n",
    "#TODO: Right now I can map things to amt for example which should not be the case...\n",
    "#dd =dd[dd.art='sogn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding countries (Barbara's list, but missing countries before the german, and italian unifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length original:\t 2519 \n",
      "length modified:\t 26874 \n",
      "unique sogn keys:\t 1924\n"
     ]
    }
   ],
   "source": [
    "print('length original:\\t', len(dd_org), '\\nlength modified:\\t', len(dd), '\\nunique sogn keys:\\t', nr_sogn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the df from the $ separated file (for some reason pandas has problems with random lines)\n",
    "def get_df(f_path):\n",
    "    r= []\n",
    "    columns = []\n",
    "    with open(f_path) as f:\n",
    "        first = True\n",
    "        for line in f:\n",
    "            line = line.rstrip().split('$')\n",
    "            if first:\n",
    "                length = len(line)\n",
    "                columns = line\n",
    "                first=False\n",
    "            else:\n",
    "                r.append(line[:length])\n",
    "                \n",
    "    return pd.DataFrame(data=r, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name cleaning function\n",
    "def name_cleaner(s, working_column):\n",
    "    try:\n",
    "        o = s[working_column].lower().rstrip().replace('  ', ' ')\n",
    "        #if it says \"her i sogn\", I get the value for \"Sogn\" and put it there\n",
    "        if ('heri sogn' in o or 'her i sogn' in o or 'her i s.' == o or 'i sognet' == o) and working_column != 'Sogne':\n",
    "            return name_cleaner(s, 'Sogne')\n",
    "        return o\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of files to work (with the 1901 collapsed)\n",
    "#This I did\n",
    "working_data = ['ft1845_LL.txt',\n",
    " 'ft1850_LL.txt',\n",
    " 'ft1860_LL.txt',\n",
    " 'ft1880_LL.txt',\n",
    " 'ft1885_LL.txt',\n",
    " 'ft1901_LL.txt']\n",
    "\n",
    "#This Nicolai\n",
    "working_data = ['ft1787.txt',\n",
    "'ft1801.txt',\n",
    "'ft1803.txt',\n",
    "'ft1834.txt',\n",
    "'ft1840.txt',\n",
    "'ft1845.txt',\n",
    "'ft1850.txt',\n",
    "'ft1860.txt',\n",
    "'ft1880.txt',\n",
    "'ft1885.txt',\n",
    "'ft1901.txt']\n",
    "\n",
    "#This Nicolai\n",
    "working_data = ['ft1845.txt',\n",
    "'ft1850.txt',\n",
    "'ft1860.txt',\n",
    "'ft1880.txt',\n",
    "'ft1885.txt',\n",
    "'ft1901.txt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data and counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft1845.txt\n",
      "1281746\n",
      "ft1850.txt\n",
      "1359777\n",
      "ft1860.txt\n",
      "1700886\n",
      "ft1880.txt\n",
      "1759664\n",
      "ft1885.txt\n",
      "318056\n",
      "ft1901.txt\n",
      "2046684\n",
      "Done! :D\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fødested_data</th>\n",
       "      <th>counts</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>19478</td>\n",
       "      <td>kjøbenhavn</td>\n",
       "      <td>131940</td>\n",
       "      <td>1885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53019</td>\n",
       "      <td>kjøbenhavn</td>\n",
       "      <td>85461</td>\n",
       "      <td>1860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70334</td>\n",
       "      <td>kjøbenhavn</td>\n",
       "      <td>69835</td>\n",
       "      <td>1880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74519</td>\n",
       "      <td>københavn</td>\n",
       "      <td>67981</td>\n",
       "      <td>1880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99006</td>\n",
       "      <td>københavn</td>\n",
       "      <td>58674</td>\n",
       "      <td>1901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87026</td>\n",
       "      <td>staun, farstrup sogn, aalborg amt</td>\n",
       "      <td>1</td>\n",
       "      <td>1860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87025</td>\n",
       "      <td>staun, brandenburg</td>\n",
       "      <td>1</td>\n",
       "      <td>1860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87023</td>\n",
       "      <td>staun sogn</td>\n",
       "      <td>1</td>\n",
       "      <td>1860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87022</td>\n",
       "      <td>staun i svansøe. s??by sogn</td>\n",
       "      <td>1</td>\n",
       "      <td>1860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212846</td>\n",
       "      <td>…?? …?? …??</td>\n",
       "      <td>1</td>\n",
       "      <td>1901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>738826 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            fødested_data  counts  year\n",
       "19478                          kjøbenhavn  131940  1885\n",
       "53019                          kjøbenhavn   85461  1860\n",
       "70334                          kjøbenhavn   69835  1880\n",
       "74519                           københavn   67981  1880\n",
       "99006                           københavn   58674  1901\n",
       "...                                   ...     ...   ...\n",
       "87026   staun, farstrup sogn, aalborg amt       1  1860\n",
       "87025                  staun, brandenburg       1  1860\n",
       "87023                          staun sogn       1  1860\n",
       "87022         staun i svansøe. s??by sogn       1  1860\n",
       "212846                        …?? …?? …??       1  1901\n",
       "\n",
       "[738826 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is where I save the counts and then group it together\n",
    "out_list = []\n",
    "\n",
    "#where I save the missmatches and file year\n",
    "missmatches = []\n",
    "total_records = 0\n",
    "\n",
    "for f in working_data:\n",
    "    \n",
    "    print(f)\n",
    "    #Loading the data\n",
    "    df = get_df(in_folder+f)\n",
    "    \n",
    "    #Dropping empty rows due to the \"mal-conversion\" to utf8... The empty rows do contain data originally\n",
    "    #TODO: Fix the conversion thing (ask Barbara to provide me the UTF-8...)\n",
    "    df = df[~df[focus_column].isna() & (df[focus_column] !='')]\n",
    "    print(len(df))\n",
    "    total_records = total_records + len(df)\n",
    "    \n",
    "    #Preforming the name cleaning, be aware that I replace \"her i sogn\" in there\n",
    "    df[focus_column+'_data'] = df.apply(lambda row: name_cleaner(row, focus_column), axis=1)\n",
    "    \n",
    "    #Reducing Dimensionality and saving in RAM\n",
    "    out = df.groupby(focus_column+'_data').size().reset_index(name = 'counts')\n",
    "    out['year'] = f[2:6]\n",
    "    out_list.append(out)\n",
    "\n",
    "    \n",
    "out_list = pd.concat(out_list, sort=False)\n",
    "print('Done! :D')\n",
    "del df\n",
    "total_people = out_list.counts.sum()\n",
    "total_num_places = len(out_list[focus_column+'_data'])\n",
    "out_list.sort_values('counts',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fødested_data</th>\n",
       "      <th>1845</th>\n",
       "      <th>1850</th>\n",
       "      <th>1860</th>\n",
       "      <th>1880</th>\n",
       "      <th>1885</th>\n",
       "      <th>1901</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>272800</td>\n",
       "      <td>kjøbenhavn</td>\n",
       "      <td>46621</td>\n",
       "      <td>43550</td>\n",
       "      <td>85461</td>\n",
       "      <td>69835</td>\n",
       "      <td>131940</td>\n",
       "      <td>30187</td>\n",
       "      <td>407594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>289033</td>\n",
       "      <td>københavn</td>\n",
       "      <td>14221</td>\n",
       "      <td>9331</td>\n",
       "      <td>16227</td>\n",
       "      <td>67981</td>\n",
       "      <td>14500</td>\n",
       "      <td>58674</td>\n",
       "      <td>180934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>358825</td>\n",
       "      <td>odense</td>\n",
       "      <td>8196</td>\n",
       "      <td>6485</td>\n",
       "      <td>9269</td>\n",
       "      <td>12991</td>\n",
       "      <td>2967</td>\n",
       "      <td>23096</td>\n",
       "      <td>63004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18133</td>\n",
       "      <td>aalborg</td>\n",
       "      <td>5747</td>\n",
       "      <td>2691</td>\n",
       "      <td>8044</td>\n",
       "      <td>9797</td>\n",
       "      <td>2103</td>\n",
       "      <td>15702</td>\n",
       "      <td>44084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19805</td>\n",
       "      <td>aarhus</td>\n",
       "      <td>4044</td>\n",
       "      <td>4577</td>\n",
       "      <td>1710</td>\n",
       "      <td>3043</td>\n",
       "      <td>1818</td>\n",
       "      <td>23640</td>\n",
       "      <td>38832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222805</td>\n",
       "      <td>horsens</td>\n",
       "      <td>4105</td>\n",
       "      <td>3091</td>\n",
       "      <td>5681</td>\n",
       "      <td>8026</td>\n",
       "      <td>1390</td>\n",
       "      <td>12564</td>\n",
       "      <td>34857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201057</td>\n",
       "      <td>helsingør</td>\n",
       "      <td>1140</td>\n",
       "      <td>5801</td>\n",
       "      <td>6771</td>\n",
       "      <td>7643</td>\n",
       "      <td>2966</td>\n",
       "      <td>7898</td>\n",
       "      <td>32219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102856</td>\n",
       "      <td>do.</td>\n",
       "      <td>10</td>\n",
       "      <td>21321</td>\n",
       "      <td>6</td>\n",
       "      <td>5163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140134</td>\n",
       "      <td>fredericia</td>\n",
       "      <td>3678</td>\n",
       "      <td>2438</td>\n",
       "      <td>5155</td>\n",
       "      <td>4212</td>\n",
       "      <td>918</td>\n",
       "      <td>8057</td>\n",
       "      <td>24458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>376339</td>\n",
       "      <td>randers</td>\n",
       "      <td>1814</td>\n",
       "      <td>4050</td>\n",
       "      <td>7380</td>\n",
       "      <td>3309</td>\n",
       "      <td>1763</td>\n",
       "      <td>4867</td>\n",
       "      <td>23183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>467677</td>\n",
       "      <td>sverrig</td>\n",
       "      <td>709</td>\n",
       "      <td>1803</td>\n",
       "      <td>4114</td>\n",
       "      <td>6529</td>\n",
       "      <td>4004</td>\n",
       "      <td>5954</td>\n",
       "      <td>23113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>434012</td>\n",
       "      <td>slagelse</td>\n",
       "      <td>2748</td>\n",
       "      <td>2975</td>\n",
       "      <td>3776</td>\n",
       "      <td>5308</td>\n",
       "      <td>2104</td>\n",
       "      <td>4875</td>\n",
       "      <td>21786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>466244</td>\n",
       "      <td>svendborg</td>\n",
       "      <td>2025</td>\n",
       "      <td>1005</td>\n",
       "      <td>4141</td>\n",
       "      <td>4692</td>\n",
       "      <td>1031</td>\n",
       "      <td>7279</td>\n",
       "      <td>20173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>467604</td>\n",
       "      <td>sverige</td>\n",
       "      <td>227</td>\n",
       "      <td>1028</td>\n",
       "      <td>3637</td>\n",
       "      <td>6022</td>\n",
       "      <td>2779</td>\n",
       "      <td>6013</td>\n",
       "      <td>19706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>549360</td>\n",
       "      <td>viborg</td>\n",
       "      <td>848</td>\n",
       "      <td>2504</td>\n",
       "      <td>4022</td>\n",
       "      <td>4773</td>\n",
       "      <td>846</td>\n",
       "      <td>5754</td>\n",
       "      <td>18747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>345126</td>\n",
       "      <td>nyborg</td>\n",
       "      <td>1957</td>\n",
       "      <td>2779</td>\n",
       "      <td>3340</td>\n",
       "      <td>3557</td>\n",
       "      <td>973</td>\n",
       "      <td>4914</td>\n",
       "      <td>17520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>435396</td>\n",
       "      <td>slesvig</td>\n",
       "      <td>272</td>\n",
       "      <td>3243</td>\n",
       "      <td>1752</td>\n",
       "      <td>7236</td>\n",
       "      <td>844</td>\n",
       "      <td>3665</td>\n",
       "      <td>17012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140604</td>\n",
       "      <td>frederiksberg</td>\n",
       "      <td>689</td>\n",
       "      <td>256</td>\n",
       "      <td>1076</td>\n",
       "      <td>3213</td>\n",
       "      <td>5952</td>\n",
       "      <td>5293</td>\n",
       "      <td>16479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>278666</td>\n",
       "      <td>kolding</td>\n",
       "      <td>790</td>\n",
       "      <td>1029</td>\n",
       "      <td>2928</td>\n",
       "      <td>4392</td>\n",
       "      <td>706</td>\n",
       "      <td>6362</td>\n",
       "      <td>16207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>269389</td>\n",
       "      <td>kiøbenhavn</td>\n",
       "      <td>7696</td>\n",
       "      <td>3541</td>\n",
       "      <td>1997</td>\n",
       "      <td>644</td>\n",
       "      <td>1581</td>\n",
       "      <td>93</td>\n",
       "      <td>15552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>336310</td>\n",
       "      <td>nakskov</td>\n",
       "      <td>1847</td>\n",
       "      <td>2206</td>\n",
       "      <td>2822</td>\n",
       "      <td>1474</td>\n",
       "      <td>1003</td>\n",
       "      <td>4914</td>\n",
       "      <td>14266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>491178</td>\n",
       "      <td>thisted</td>\n",
       "      <td>1334</td>\n",
       "      <td>1870</td>\n",
       "      <td>2509</td>\n",
       "      <td>2834</td>\n",
       "      <td>596</td>\n",
       "      <td>3595</td>\n",
       "      <td>12738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>-</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>12598</td>\n",
       "      <td>12699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37470</td>\n",
       "      <td>assens</td>\n",
       "      <td>2192</td>\n",
       "      <td>1806</td>\n",
       "      <td>3012</td>\n",
       "      <td>1516</td>\n",
       "      <td>638</td>\n",
       "      <td>3339</td>\n",
       "      <td>12503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5923</td>\n",
       "      <td>??</td>\n",
       "      <td>1868</td>\n",
       "      <td>1158</td>\n",
       "      <td>2513</td>\n",
       "      <td>4417</td>\n",
       "      <td>141</td>\n",
       "      <td>2184</td>\n",
       "      <td>12281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>388795</td>\n",
       "      <td>roskilde</td>\n",
       "      <td>401</td>\n",
       "      <td>2119</td>\n",
       "      <td>952</td>\n",
       "      <td>2574</td>\n",
       "      <td>1302</td>\n",
       "      <td>4824</td>\n",
       "      <td>12172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395699</td>\n",
       "      <td>rønne</td>\n",
       "      <td>406</td>\n",
       "      <td>794</td>\n",
       "      <td>1035</td>\n",
       "      <td>3226</td>\n",
       "      <td>692</td>\n",
       "      <td>5769</td>\n",
       "      <td>11922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214442</td>\n",
       "      <td>hjørring</td>\n",
       "      <td>982</td>\n",
       "      <td>759</td>\n",
       "      <td>1429</td>\n",
       "      <td>2893</td>\n",
       "      <td>413</td>\n",
       "      <td>4216</td>\n",
       "      <td>10692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281576</td>\n",
       "      <td>korsør</td>\n",
       "      <td>233</td>\n",
       "      <td>1219</td>\n",
       "      <td>1509</td>\n",
       "      <td>3070</td>\n",
       "      <td>702</td>\n",
       "      <td>3713</td>\n",
       "      <td>10446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>327285</td>\n",
       "      <td>middelfart</td>\n",
       "      <td>1421</td>\n",
       "      <td>1495</td>\n",
       "      <td>1850</td>\n",
       "      <td>2245</td>\n",
       "      <td>318</td>\n",
       "      <td>2583</td>\n",
       "      <td>9912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>341988</td>\n",
       "      <td>nordby</td>\n",
       "      <td>2426</td>\n",
       "      <td>2506</td>\n",
       "      <td>2547</td>\n",
       "      <td>1036</td>\n",
       "      <td>3</td>\n",
       "      <td>1335</td>\n",
       "      <td>9853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106941</td>\n",
       "      <td>dronninglund</td>\n",
       "      <td>2638</td>\n",
       "      <td>3084</td>\n",
       "      <td>27</td>\n",
       "      <td>2167</td>\n",
       "      <td>15</td>\n",
       "      <td>1806</td>\n",
       "      <td>9737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497141</td>\n",
       "      <td>tikøb</td>\n",
       "      <td>3705</td>\n",
       "      <td>3271</td>\n",
       "      <td>10</td>\n",
       "      <td>2463</td>\n",
       "      <td>29</td>\n",
       "      <td>126</td>\n",
       "      <td>9604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470047</td>\n",
       "      <td>sæby</td>\n",
       "      <td>1232</td>\n",
       "      <td>1720</td>\n",
       "      <td>2504</td>\n",
       "      <td>2398</td>\n",
       "      <td>185</td>\n",
       "      <td>1546</td>\n",
       "      <td>9585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>537613</td>\n",
       "      <td>veile</td>\n",
       "      <td>327</td>\n",
       "      <td>1963</td>\n",
       "      <td>2722</td>\n",
       "      <td>3374</td>\n",
       "      <td>665</td>\n",
       "      <td>502</td>\n",
       "      <td>9553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>382048</td>\n",
       "      <td>ribe</td>\n",
       "      <td>1893</td>\n",
       "      <td>586</td>\n",
       "      <td>2824</td>\n",
       "      <td>2607</td>\n",
       "      <td>446</td>\n",
       "      <td>1135</td>\n",
       "      <td>9491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216087</td>\n",
       "      <td>holbæk</td>\n",
       "      <td>680</td>\n",
       "      <td>775</td>\n",
       "      <td>989</td>\n",
       "      <td>3051</td>\n",
       "      <td>1070</td>\n",
       "      <td>2717</td>\n",
       "      <td>9282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350523</td>\n",
       "      <td>næstved</td>\n",
       "      <td>397</td>\n",
       "      <td>986</td>\n",
       "      <td>2079</td>\n",
       "      <td>1948</td>\n",
       "      <td>681</td>\n",
       "      <td>3076</td>\n",
       "      <td>9167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90528</td>\n",
       "      <td>do</td>\n",
       "      <td>0</td>\n",
       "      <td>8503</td>\n",
       "      <td>433</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183607</td>\n",
       "      <td>haderslev</td>\n",
       "      <td>657</td>\n",
       "      <td>547</td>\n",
       "      <td>5514</td>\n",
       "      <td>1058</td>\n",
       "      <td>472</td>\n",
       "      <td>803</td>\n",
       "      <td>9051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124310</td>\n",
       "      <td>faaborg</td>\n",
       "      <td>1031</td>\n",
       "      <td>597</td>\n",
       "      <td>2229</td>\n",
       "      <td>1859</td>\n",
       "      <td>586</td>\n",
       "      <td>2602</td>\n",
       "      <td>8904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395737</td>\n",
       "      <td>rønne købstad - bornholms amt</td>\n",
       "      <td>2967</td>\n",
       "      <td>2747</td>\n",
       "      <td>3122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>467560</td>\n",
       "      <td>sverig</td>\n",
       "      <td>33</td>\n",
       "      <td>215</td>\n",
       "      <td>850</td>\n",
       "      <td>2522</td>\n",
       "      <td>1115</td>\n",
       "      <td>3976</td>\n",
       "      <td>8711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384968</td>\n",
       "      <td>ringsted</td>\n",
       "      <td>1222</td>\n",
       "      <td>1320</td>\n",
       "      <td>1645</td>\n",
       "      <td>1885</td>\n",
       "      <td>816</td>\n",
       "      <td>1641</td>\n",
       "      <td>8529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20014</td>\n",
       "      <td>aarhuus</td>\n",
       "      <td>1459</td>\n",
       "      <td>1415</td>\n",
       "      <td>4332</td>\n",
       "      <td>547</td>\n",
       "      <td>391</td>\n",
       "      <td>179</td>\n",
       "      <td>8323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>533722</td>\n",
       "      <td>varde</td>\n",
       "      <td>289</td>\n",
       "      <td>1178</td>\n",
       "      <td>1730</td>\n",
       "      <td>1948</td>\n",
       "      <td>255</td>\n",
       "      <td>2808</td>\n",
       "      <td>8208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148812</td>\n",
       "      <td>født i sognet</td>\n",
       "      <td>2471</td>\n",
       "      <td>5115</td>\n",
       "      <td>533</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>319185</td>\n",
       "      <td>magleby</td>\n",
       "      <td>1388</td>\n",
       "      <td>3299</td>\n",
       "      <td>1808</td>\n",
       "      <td>926</td>\n",
       "      <td>49</td>\n",
       "      <td>511</td>\n",
       "      <td>7981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58307</td>\n",
       "      <td>bogense</td>\n",
       "      <td>1169</td>\n",
       "      <td>1251</td>\n",
       "      <td>1611</td>\n",
       "      <td>1805</td>\n",
       "      <td>347</td>\n",
       "      <td>1699</td>\n",
       "      <td>7882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>423916</td>\n",
       "      <td>skive</td>\n",
       "      <td>793</td>\n",
       "      <td>994</td>\n",
       "      <td>1310</td>\n",
       "      <td>1747</td>\n",
       "      <td>253</td>\n",
       "      <td>2485</td>\n",
       "      <td>7582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        fødested_data   1845   1850   1860   1880    1885  \\\n",
       "272800                     kjøbenhavn  46621  43550  85461  69835  131940   \n",
       "289033                      københavn  14221   9331  16227  67981   14500   \n",
       "358825                         odense   8196   6485   9269  12991    2967   \n",
       "18133                         aalborg   5747   2691   8044   9797    2103   \n",
       "19805                          aarhus   4044   4577   1710   3043    1818   \n",
       "222805                        horsens   4105   3091   5681   8026    1390   \n",
       "201057                      helsingør   1140   5801   6771   7643    2966   \n",
       "102856                            do.     10  21321      6   5163       0   \n",
       "140134                     fredericia   3678   2438   5155   4212     918   \n",
       "376339                        randers   1814   4050   7380   3309    1763   \n",
       "467677                        sverrig    709   1803   4114   6529    4004   \n",
       "434012                       slagelse   2748   2975   3776   5308    2104   \n",
       "466244                      svendborg   2025   1005   4141   4692    1031   \n",
       "467604                        sverige    227   1028   3637   6022    2779   \n",
       "549360                         viborg    848   2504   4022   4773     846   \n",
       "345126                         nyborg   1957   2779   3340   3557     973   \n",
       "435396                        slesvig    272   3243   1752   7236     844   \n",
       "140604                  frederiksberg    689    256   1076   3213    5952   \n",
       "278666                        kolding    790   1029   2928   4392     706   \n",
       "269389                     kiøbenhavn   7696   3541   1997    644    1581   \n",
       "336310                        nakskov   1847   2206   2822   1474    1003   \n",
       "491178                        thisted   1334   1870   2509   2834     596   \n",
       "33                                  -     21      4     57     19       0   \n",
       "37470                          assens   2192   1806   3012   1516     638   \n",
       "5923                               ??   1868   1158   2513   4417     141   \n",
       "388795                       roskilde    401   2119    952   2574    1302   \n",
       "395699                          rønne    406    794   1035   3226     692   \n",
       "214442                       hjørring    982    759   1429   2893     413   \n",
       "281576                         korsør    233   1219   1509   3070     702   \n",
       "327285                     middelfart   1421   1495   1850   2245     318   \n",
       "341988                         nordby   2426   2506   2547   1036       3   \n",
       "106941                   dronninglund   2638   3084     27   2167      15   \n",
       "497141                          tikøb   3705   3271     10   2463      29   \n",
       "470047                           sæby   1232   1720   2504   2398     185   \n",
       "537613                          veile    327   1963   2722   3374     665   \n",
       "382048                           ribe   1893    586   2824   2607     446   \n",
       "216087                         holbæk    680    775    989   3051    1070   \n",
       "350523                        næstved    397    986   2079   1948     681   \n",
       "90528                              do      0   8503    433     14       0   \n",
       "183607                      haderslev    657    547   5514   1058     472   \n",
       "124310                        faaborg   1031    597   2229   1859     586   \n",
       "395737  rønne købstad - bornholms amt   2967   2747   3122      0       0   \n",
       "467560                         sverig     33    215    850   2522    1115   \n",
       "384968                       ringsted   1222   1320   1645   1885     816   \n",
       "20014                         aarhuus   1459   1415   4332    547     391   \n",
       "533722                          varde    289   1178   1730   1948     255   \n",
       "148812                  født i sognet   2471   5115    533     53       0   \n",
       "319185                        magleby   1388   3299   1808    926      49   \n",
       "58307                         bogense   1169   1251   1611   1805     347   \n",
       "423916                          skive    793    994   1310   1747     253   \n",
       "\n",
       "         1901   total  \n",
       "272800  30187  407594  \n",
       "289033  58674  180934  \n",
       "358825  23096   63004  \n",
       "18133   15702   44084  \n",
       "19805   23640   38832  \n",
       "222805  12564   34857  \n",
       "201057   7898   32219  \n",
       "102856      0   26500  \n",
       "140134   8057   24458  \n",
       "376339   4867   23183  \n",
       "467677   5954   23113  \n",
       "434012   4875   21786  \n",
       "466244   7279   20173  \n",
       "467604   6013   19706  \n",
       "549360   5754   18747  \n",
       "345126   4914   17520  \n",
       "435396   3665   17012  \n",
       "140604   5293   16479  \n",
       "278666   6362   16207  \n",
       "269389     93   15552  \n",
       "336310   4914   14266  \n",
       "491178   3595   12738  \n",
       "33      12598   12699  \n",
       "37470    3339   12503  \n",
       "5923     2184   12281  \n",
       "388795   4824   12172  \n",
       "395699   5769   11922  \n",
       "214442   4216   10692  \n",
       "281576   3713   10446  \n",
       "327285   2583    9912  \n",
       "341988   1335    9853  \n",
       "106941   1806    9737  \n",
       "497141    126    9604  \n",
       "470047   1546    9585  \n",
       "537613    502    9553  \n",
       "382048   1135    9491  \n",
       "216087   2717    9282  \n",
       "350523   3076    9167  \n",
       "90528     143    9093  \n",
       "183607    803    9051  \n",
       "124310   2602    8904  \n",
       "395737      0    8836  \n",
       "467560   3976    8711  \n",
       "384968   1641    8529  \n",
       "20014     179    8323  \n",
       "533722   2808    8208  \n",
       "148812      4    8176  \n",
       "319185    511    7981  \n",
       "58307    1699    7882  \n",
       "423916   2485    7582  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Putting it nicely, on a more horitzontal table\n",
    "out_list = out_list.pivot(focus_column+'_data', 'year', 'counts').fillna(0).astype(int).reset_index().reset_index(drop=True)\n",
    "out_list = pd.DataFrame(out_list.values, columns=out_list.columns.tolist()) #Getting rid of the wrong index\n",
    "out_list['total'] = out_list.apply(lambda row: row['1845']+row['1850']+row['1860']+row['1880']+row['1885']+row['1901'],axis=1)\n",
    "out_list.sort_values('total', ascending=False, inplace=True)\n",
    "out_list.total.sum() #Around the 14k first places compule 80% of the people\n",
    "out_list.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    }
   ],
   "source": [
    "#Notice that I only match for Sogn\n",
    "out = out_list.merge(dd[['navn','simplename', 'art', 'enhedid']], left_on=focus_column+'_data', right_on='simplename', how='left')\n",
    "\n",
    "#Those are the missmatch\n",
    "miss = out[out.enhedid.isna()]\n",
    "miss.head()\n",
    "\n",
    "#Here are the match\n",
    "match = out[~out.enhedid.isna()]\n",
    "match.head()\n",
    "\n",
    "# Aggregating the match by enhedid and year\n",
    "agg_counts = match.groupby(['navn', 'enhedid', 'art'],as_index = False).agg({'1845':'sum', '1850':'sum','1860':'sum', '1880':'sum','1885':'sum', '1901':'sum'})\n",
    "\n",
    "# Grouping all enhedid to see how many different versions of the same Sogne we have in the data\n",
    "diff_counts = match.groupby(['navn','enhedid'])[focus_column+'_data'].apply(set).reset_index(name='extended_digdag') #if parenthesis is confusing add **.apply(lambda x: ', '.join(x))** before the reset index\n",
    "\n",
    "# Joining DFs and saving\n",
    "s = agg_counts.merge(diff_counts, on = ['navn','enhedid'])\n",
    "s.to_csv(out_folder+'birthplaces_FT_uniquevalues_01.tsv', sep='\\t', index=False)\n",
    "print(len(s))\n",
    "s.head()\n",
    "del s, agg_counts, diff_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Jaro distances for the missmatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 2083\n",
      "100 out of 2083\n",
      "200 out of 2083\n",
      "300 out of 2083\n",
      "400 out of 2083\n",
      "500 out of 2083\n",
      "600 out of 2083\n",
      "700 out of 2083\n",
      "800 out of 2083\n"
     ]
    }
   ],
   "source": [
    "#Getting the potential first matches\n",
    "\n",
    "mm = miss[focus_column+'_data'].unique()\n",
    "sn = dd_org.simplename.unique() # Using the short version of dig dag to make it much faster (>x10)\n",
    "\n",
    "distance_jaro = np.zeros((len(sn),len(mm)))\n",
    "\n",
    "def compute_jaro(a,b):\n",
    "    try:\n",
    "        return distance.get_jaro_distance(a, b)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "for i in range(len(sn)):\n",
    "    if i%100 == 0: print(i, 'out of' , len(sn))\n",
    "        \n",
    "    #Computing jaro only\n",
    "    distance_jaro[i] = miss[focus_column+'_data'].apply(lambda x: compute_jaro(sn[i], x)).values\n",
    "    \n",
    "        \n",
    "#Index is the reference names found in digdag the columns the original data\n",
    "distance_jaro = pd.DataFrame(data = distance_jaro, columns = mm, index = sn)\n",
    "print(distance_jaro.shape, 'len mm,sn:', len(mm), len(sn)) #(26428, 1237)\n",
    "distance_jaro.head()\n",
    "del mm, sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distance_jaro.to_csv(out_folder+'jaro_birthplaces.tsv', sep='\\t', index=True)\n",
    "#distance_jaro.to_csv('/home/roregu/workspace/tmp/aux.tsv', sep='\\t', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the best match with a minimum threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Getting the highest match for each Sogne and filtering threshold\n",
    "a = distance_jaro.idxmax().reset_index(name = 'potential_match')\n",
    "b = distance_jaro.max().reset_index(name='jaro')\n",
    "dfmap = a.merge(b, on='index').rename(columns={'index':'data_name'})\n",
    "dfmap.to_csv(out_folder+'mapping_birthplaces.tsv', sep='\\t', index=False)\n",
    "dfmap = dfmap[dfmap.jaro.astype(float) >= THRESHOLD]\n",
    "dfmap.head()\n",
    "del a\n",
    "del b\n",
    "\n",
    "#Getting the mapped info into DigDag v2 (not really the v2)\n",
    "dd2 = dfmap.merge(dd[['navn','simplename', 'art', 'enhedid']].sort_values('art', ascending=False).drop_duplicates('simplename', keep='first'), left_on='potential_match', right_on='simplename')\n",
    "dd2['simplename'] = dd2['data_name']\n",
    "dd2 = dd2[['navn','enhedid','art','simplename']]\n",
    "dd2 = pd.concat([dd2[['navn','simplename', 'art', 'enhedid']], dd], sort=False) #putting together\n",
    "dd2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting again with the merges\n",
    "out = out_list.merge(dd2, left_on=focus_column+'_data', right_on='simplename', how='left')\n",
    "\n",
    "#Those are the missmatch\n",
    "miss = out[out.enhedid.isna()]\n",
    "miss.head()\n",
    "\n",
    "#Here are the match\n",
    "match = out[~out.enhedid.isna()]\n",
    "match.head()\n",
    "\n",
    "# Aggregating the match by enhedid and year\n",
    "agg_counts = match.groupby(['navn', 'enhedid', 'art'],as_index = False).agg({'1845':'sum', '1850':'sum','1860':'sum', '1880':'sum','1885':'sum', '1901':'sum'})\n",
    "\n",
    "# Grouping all enhedid to see how many different versions of the same Sogne we have in the data\n",
    "diff_counts = match.groupby(['navn','enhedid'])[focus_column+'_data'].apply(set).reset_index(name='extended_digdag') #if parenthesis is confusing add **.apply(lambda x: ', '.join(x))** before the reset index\n",
    "\n",
    "# Joining DFs and saving\n",
    "s = agg_counts.merge(diff_counts, on = ['navn','enhedid'])\n",
    "s.to_csv(out_folder+'birthplaces_FT_jaro0.9_01.tsv', sep='\\t', index=False)\n",
    "print(len(s))\n",
    "s.head()\n",
    "del s, agg_counts, diff_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the missmatches after jaro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting commas and trying to match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for bug remove if list is empty\n",
    "miss[miss[focus_column+'_data'] == 'kjøbenhavn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting te commas string\n",
    "commas = miss[miss[focus_column+'_data'].apply(lambda x: ',' in x)]\n",
    "print('This many people have commas', commas.total.sum())\n",
    "commas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commas.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### See what couldn't be matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting counts for other possible matches (broke here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is on top: distance_jaro.to_csv('/home/roregu/workspace/tmp/aux.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the best possible matches\n",
    "\n",
    "concatenate = []\n",
    "i=0\n",
    "for col in distance_jaro.columns:\n",
    "    i = i+1\n",
    "    if i % 100 == 0: print(i, 'out of', len(distance_jaro.columns))\n",
    "    aux = distance_jaro.nlargest(5, col)[[col]]\n",
    "    aux.columns = ['score']\n",
    "    aux['original'] = col\n",
    "    concatenate.append(aux)\n",
    "\n",
    "concatenate = pd.concat(concatenate, sort=False)\n",
    "concatenate = concatenate.reset_index()\n",
    "concatenate.columns = ['potential_match','score','original']\n",
    "concatenate[['original','potential_match','score']][~concatenate.original.isin(concatenate[(concatenate.score >= THRESHOLD) & ~concatenate.original.isna()].original.unique())].to_csv(_path+'../out/birthplaces_possible_matches_jaro_01.tsv', index=False, sep='\\t')\n",
    "\n",
    "concatenate = pd.read_csv(out_folder+'birthplaces_possible_matches_jaro_01.tsv',  sep='\\t')\n",
    "concatenate.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: If running this remember to uncomment few cells above so it saves the new files\n",
    "\n",
    "n_cores = 15\n",
    "jump=int(606466/n_cores) #len(distance_jaro.columns))\n",
    "a = 4\n",
    "s = ''\n",
    "for i in range(0,606466,jump):\n",
    "    \n",
    "    if a ==0:\n",
    "        print(s)\n",
    "        s=''\n",
    "        a=4\n",
    "    s = s + 'python top5_hits_par.py '+str(i)+' '+str(jump+i)+' ; '\n",
    "    a = a-1\n",
    "    \n",
    "print(s) #This is how I make sure that my own processes don't get killed and I do not need to monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'python top5_hits_par.py '+str(i)+' '+str(jump+i)+' ; '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This is the script I used to \"parallelize\" the selection of the top 5 matches per potential matches\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "_from = int(sys.argv[1])\n",
    "_to = int(sys.argv[2])\n",
    "_top = 5 #Top what? sys.argv[1]\n",
    "THRESHOLD = 0.9\n",
    "\n",
    "if os.path.isfile('/home/roregu/workspace/tmp/concatenate_'+str(_from)+'_'+str(_to)+'.tsv'):\n",
    "    print('done')\n",
    "    exit()\n",
    "\n",
    "distance_jaro = pd.read_csv('/home/roregu/workspace/aux.tsv', sep = '\\t', usecols=[0]+list(np.arange(_from,_to)), index_col=0 )\n",
    "\n",
    "#print(distance_jaro.head())\n",
    "\n",
    "concatenate = []\n",
    "i=0\n",
    "for col in distance_jaro.columns:\n",
    "    i = i+1\n",
    "    #if i % 100 == 0: print(i, 'out of', len(distance_jaro.columns))\n",
    "    aux = distance_jaro.nlargest(5, col)[[col]]\n",
    "    aux.columns = ['score']\n",
    "    aux['original'] = col\n",
    "    concatenate.append(aux)\n",
    "\n",
    "#print(concatenate)\n",
    "concatenate = pd.concat(concatenate, sort=False)\n",
    "concatenate = concatenate.reset_index()\n",
    "concatenate.columns = ['potential_match','score','original']\n",
    "#print(concatenate)\n",
    "concatenate[['original','potential_match','score']][~concatenate.original.isin(concatenate[(concatenate.score >= THRESHOLD) & ~concatenate.original.isna()].original.unique())].to_csv('/home/roregu/workspace/tmp/concatenate_'+str(_from)+'_'+str(_to)+'.tsv', index=False, sep='\\t')\n",
    "\n",
    "print('done_'+str(_from)+'_'+str(_to))\n",
    "\n",
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listing all files in directory \n",
    "concatenate = []\n",
    "for directory, _, files in os.walk('/home/roregu/workspace/tmp/'):\n",
    "    for file in files:\n",
    "        concatenate.append(pd.read_csv(directory+file, sep = '\\t', dtype=str))\n",
    "                           \n",
    "concatenate = pd.concat(concatenate, sort=False)\n",
    "concatenate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the digDag info for the matches but also for the non matches\n",
    "\n",
    "m = concatenate.merge(dd2[['navn','simplename', 'art', 'enhedid']].sort_values('art', ascending=False).drop_duplicates('simplename',keep='first'), left_on='potential_match', right_on='simplename', how='inner')\n",
    "m = m[['original','potential_match','score','navn','art','enhedid', 'simplename']]\n",
    "\n",
    "w = dd2.sort_values('art', ascending=False).drop_duplicates('simplename',keep='first')\n",
    "w['potential_match'] = w['simplename']\n",
    "w['original'] = w['simplename']\n",
    "w['score'] = 1\n",
    "\n",
    "m = pd.concat([w, m], sort=True)\n",
    "\n",
    "\n",
    "#Putting the things into place\n",
    "m['original'] = np.where(m.original.isna(), m['simplename'], m['original'])\n",
    "\n",
    "print(len(concatenate), len(m))\n",
    "m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the counts for the original plus the counts for the potential matches in DigDag\n",
    "#Warning: Potential matches may not exist in the data...\n",
    "out = m.merge(out_list, left_on='original', right_on=focus_column+'_data', how='left').merge(out_list, left_on='potential_match', right_on=focus_column+'_data', how='left').fillna(0)\n",
    "for y in ['1845', '1850', '1860', '1880', '1885', '1901']:\n",
    "    out[y] = out[y+'_x'] + out[y+'_y']\n",
    "out = out[['original', 'potential_match', 'score', 'navn', 'art', 'enhedid', '1845', '1850', '1860', '1880', '1885', '1901']].sort_values('original')\n",
    "out.to_csv(_path+'../out/birthplaces_possible_matches_jaro_01.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done! :D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/data/import/nirama/cython/')\n",
    "import jw_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the validity of jaro 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(out_folder+'birthplaces_FT_jaro0.9_01.tsv', sep = '\\t', dtype=str)\n",
    "\n",
    "max_example = 5\n",
    "\n",
    "names    = df.navn.tolist()\n",
    "extendeds = df.extended_digdag.tolist()\n",
    "\n",
    "out = []\n",
    "for name, extended in zip(names, extendeds):\n",
    "    extended = list(eval(extended))\n",
    "    #m = min(len(extended), max_example)\n",
    "    samp = random.sample(extended, k= min(len(extended), max_example))\n",
    "    for s in samp:\n",
    "        out.append([name, s])\n",
    "\n",
    "dfout = pd.DataFrame(out, columns= ['DigDag', 'matches (0.9)'])\n",
    "dfout.to_csv(out_folder+'validity_jaro.tsv', sep='\\t', index=False)\n",
    "\n",
    "! cp $out_folder/validity_jaro.tsv /data/import/roc/validity_jaro.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls /data/import/roc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of non mapped 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the highest match for each Sogne and filtering threshold\n",
    "a = distance_jaro.idxmax().reset_index(name = 'potential_match')\n",
    "b = distance_jaro.max().reset_index(name='jaro')\n",
    "dfmap = a.merge(b, on='index').rename(columns={'index':'data_name'})\n",
    "dfmap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmap[dfmap.jaro < 0.9]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
