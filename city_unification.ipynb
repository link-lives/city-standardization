{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries for data management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Importing libraries for system management\n",
    "import os\n",
    "\n",
    "#Distance computation\n",
    "from pyjarowinkler import distance\n",
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Check if Danish computers have the same problem...\n",
    "I_want_to_run_all_the_preprocessing = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the current format (ISO-8859-14) into UTF-8 \n",
    "iconv -f ISO-8859-14 file_in.csv > file_out.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if I_want_to_run_all_the_preprocessing:\n",
    "    \n",
    "    #Copying into a new directory\n",
    "    ! cp -R ../../city_dump/data/LL/ ../../city_dump/data/utf8/\n",
    "\n",
    "    #Getting all files\n",
    "    d_path = '../../city_dump/data/utf8/'\n",
    "    l = next(os.walk(d_path))[2]\n",
    "\n",
    "    #Converting the files to utf8 (not sure this will work in computers different than mac...)\n",
    "    for file in l:\n",
    "        f_path = d_path+file\n",
    "        tmp_path = d_path+'tmp.csv'\n",
    "        ! iconv -f ISO-8859-14 $f_path > $tmp_path\n",
    "        !mv $tmp_path $f_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading DigDag\n",
    "and transforming it so I encode as many logical variation of the names as possible. In this way the variations for each place is only appied once whereas if we do the same for the data it will need to be applied to each place taking much longer. But the way to remember the original variation is to keep the \"enhedid\", which is the reference id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function adds extra rows in the dataframe *dd* for the \n",
    "# places where *word* exists and replaces it with *replacement*\n",
    "def adding_extra_rows(dd, word, replacement):\n",
    "    dd['special'] = dd['simplename'].apply(lambda x: word in x) \n",
    "    dd['simplename2'] = dd.simplename.apply(lambda x: x.replace(word,replacement))\n",
    "    return pd.concat([dd[['navn', 'enhedid', 'enhedtype', 'art', 'simplename']],dd[dd['special']][['navn', 'enhedid', 'enhedtype', 'art', 'simplename2']].rename(columns={'simplename2':'simplename'})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>navn</th>\n",
       "      <th>enhedid</th>\n",
       "      <th>enhedtype</th>\n",
       "      <th>art</th>\n",
       "      <th>simplename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kronborg Amt</td>\n",
       "      <td>118765</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>kronborg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Præstø Amt</td>\n",
       "      <td>118791</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>præstø</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bornholms Amt</td>\n",
       "      <td>118792</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>bornholms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Svendborg Amt</td>\n",
       "      <td>118813</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>svendborg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ålborg Amt</td>\n",
       "      <td>118819</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>ålborg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sorø Amt</td>\n",
       "      <td>118785</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>sorø</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Århus Amt</td>\n",
       "      <td>118846</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>århus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hjørring Amt</td>\n",
       "      <td>118820</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>hjørring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bøvling Amt</td>\n",
       "      <td>118851</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>bøvling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vejle Amt</td>\n",
       "      <td>118849</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>vejle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dueholm Amt</td>\n",
       "      <td>118821</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>dueholm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ørum Amt</td>\n",
       "      <td>118824</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>ørum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Thisted Amt</td>\n",
       "      <td>118826</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>thisted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Viborg Amt</td>\n",
       "      <td>118830</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>viborg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ringkøbing Amt</td>\n",
       "      <td>118853</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>ringkøbing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Københavns Kommune</td>\n",
       "      <td>370923</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>københavns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Frederiksberg Kommune</td>\n",
       "      <td>370924</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>frederiksberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fyns Amt</td>\n",
       "      <td>118739</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>fyns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sæbygård Amt</td>\n",
       "      <td>118773</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>sæbygård</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ribe Amt</td>\n",
       "      <td>118855</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>ribe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     navn enhedid enhedtype  art     simplename\n",
       "0            Kronborg Amt  118765        11  amt       kronborg\n",
       "1              Præstø Amt  118791        11  amt         præstø\n",
       "2           Bornholms Amt  118792        11  amt      bornholms\n",
       "3           Svendborg Amt  118813        11  amt      svendborg\n",
       "4              Ålborg Amt  118819        11  amt         ålborg\n",
       "5                Sorø Amt  118785        11  amt           sorø\n",
       "6               Århus Amt  118846        11  amt          århus\n",
       "7            Hjørring Amt  118820        11  amt       hjørring\n",
       "8             Bøvling Amt  118851        11  amt        bøvling\n",
       "9               Vejle Amt  118849        11  amt          vejle\n",
       "10            Dueholm Amt  118821        11  amt        dueholm\n",
       "11               Ørum Amt  118824        11  amt           ørum\n",
       "12            Thisted Amt  118826        11  amt        thisted\n",
       "13             Viborg Amt  118830        11  amt         viborg\n",
       "14         Ringkøbing Amt  118853        11  amt     ringkøbing\n",
       "15     Københavns Kommune  370923        11  amt     københavns\n",
       "16  Frederiksberg Kommune  370924        11  amt  frederiksberg\n",
       "17               Fyns Amt  118739        11  amt           fyns\n",
       "18           Sæbygård Amt  118773        11  amt       sæbygård\n",
       "19               Ribe Amt  118855        11  amt           ribe"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The digdag seems to have duplicates which I do not understand why\n",
    "dd = pd.read_csv('../../city_dump/data/rl_places_digdag_v1.txt', sep = '\\t', encoding='utf-16', dtype=str)\n",
    "dd_org = dd.copy()\n",
    "\n",
    "#Getting the Købstad and putting it to the original data\n",
    "dd2 = pd.read_csv('../../city_dump/data/koebstad.csv', sep = ';', encoding='utf-8', dtype=str)\n",
    "dd2['enhedtype'] = dd2['art'] \n",
    "dd = pd.concat([dd, dd2[~dd2.isna()][['navn','enhedid','enhedtype','art','simplename']]])\n",
    "dd['simplename'] = dd['simplename'].astype(str)\n",
    "\n",
    "#adding a conversion of special characters to latin letters (å -> aa, ø -> oe, æ -> ae) and adding them to the reference list\n",
    "dd = adding_extra_rows(dd, 'å', 'aa')\n",
    "dd = adding_extra_rows(dd, 'ø', 'oe')\n",
    "dd = adding_extra_rows(dd, 'æ', 'ae')\n",
    "\n",
    "#Preparing the names to append them at the simple name\n",
    "dd['art'] = dd['art'].apply({'Amt':'amt', 'Sogn':'sogn','Købstadskommune':'købstad', 'Geografisk Herred':'herred', 'Processing':''}.get)\n",
    "\n",
    "#Adding a duplicated list of their unit type to increase matches\n",
    "dd['simplename2'] = dd.apply(lambda row: str(row['simplename'])+' '+str(row['art']), axis=1)\n",
    "dd = pd.concat([dd[['navn', 'enhedid', 'enhedtype', 'art', 'simplename']],dd[['navn', 'enhedid', 'enhedtype', 'art', 'simplename2']].rename(columns={'simplename2':'simplename'})])\n",
    "\n",
    "#Adding the plural købstæder as well\n",
    "dd = adding_extra_rows(dd, 'købstad', 'købstæder')\n",
    "\n",
    "#Adding spaces instead of hyphens (new rows)\n",
    "dd = adding_extra_rows(dd, '-', ' ')\n",
    "\n",
    "#Removing spaces (new rows)\n",
    "dd = adding_extra_rows(dd, ' ', '')\n",
    "\n",
    "#Adding bysogn and landsogn (new rows)\n",
    "dd = adding_extra_rows(dd, 'sogn', 'bysogn')\n",
    "dd = adding_extra_rows(dd, 'sogn', 'landsogn')\n",
    "\n",
    "#adding rows where the last letter's \"e\" will be removed\n",
    "dd['special'] = dd['simplename'].str[-1] == 'e'\n",
    "dd['simplename2'] = dd['simplename'].str[:-1]\n",
    "dd = pd.concat([dd[['navn', 'enhedid', 'enhedtype', 'art', 'simplename']],dd[dd['special']][['navn', 'enhedid', 'enhedtype', 'art', 'simplename2']].rename(columns={'simplename2':'simplename'})])\n",
    "\n",
    "#Dropping duplicates from digdag\n",
    "#print(dd[dd.duplicated('simplename', keep=False)].sort_values('simplename').head(30))\n",
    "dd.drop_duplicates(['art','simplename'], keep='first', inplace=True)\n",
    "\n",
    "#Drop 'Non' from the list, this may be one of my artifacts...\n",
    "dd = dd[(dd.simplename.apply(lambda x: not 'Non' in x))]\n",
    "\n",
    "# TODO take into consideration that the same city name can be in varios geographical areas...\n",
    "# It should be matched with herred to increase accuracy for each record. However, right now we're only cleaning\n",
    "nr_sogn = len(dd_org[dd_org.art=='Sogn'].simplename.unique()) \n",
    "dd.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length original:\t 2519 \n",
      "length modified:\t 26872 \n",
      "unique sogn keys:\t 1924\n"
     ]
    }
   ],
   "source": [
    "print('length original:\\t', len(dd_org), '\\nlength modified:\\t', len(dd), '\\nunique sogn keys:\\t', nr_sogn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the df from the $ separated file (for some reason pandas has problems with random lines)\n",
    "def get_df(f_path):\n",
    "    r= []\n",
    "    columns = []\n",
    "    with open(f_path) as f:\n",
    "        first = True\n",
    "        for line in f:\n",
    "            line = line.rstrip().split('$')\n",
    "            if first:\n",
    "                length = len(line)\n",
    "                columns = line\n",
    "                first=False\n",
    "            else:\n",
    "                r.append(line[:length])\n",
    "                \n",
    "    return pd.DataFrame(data=r, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name cleaning function\n",
    "def name_cleaner(s):\n",
    "    try:\n",
    "        o =s[working_column].lower().rstrip().replace('  ', ' ')#.replace(' købstad', '')\n",
    "        if ' (' in o: return o.split(' (')[0]\n",
    "        return o\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping all 1901 files together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if I_want_to_run_all_the_preprocessing:\n",
    "    \n",
    "    l =['ft1901_LL_aalborg.txt',\n",
    "     'ft1901_LL_aarhus.txt',\n",
    "     'ft1901_LL_bornholm.txt',\n",
    "     'ft1901_LL_frederiksborg.txt',\n",
    "     'ft1901_LL_hjoerring.txt',\n",
    "     'ft1901_LL_holbaek.txt',\n",
    "     'ft1901_LL_kbhv.txt',\n",
    "     'ft1901_LL_maribo.txt',\n",
    "     'ft1901_LL_odense.txt',\n",
    "     'ft1901_LL_praestoe.txt',\n",
    "     'ft1901_LL_randers.txt',\n",
    "     'ft1901_LL_ribe.txt',\n",
    "     'ft1901_LL_ringkoebing.txt',\n",
    "     'ft1901_LL_roskilde.txt',\n",
    "     'ft1901_LL_skanderborg.txt',\n",
    "     'ft1901_LL_soroe.txt',\n",
    "     'ft1901_LL_svendborg.txt',\n",
    "     'ft1901_LL_thisted.txt',\n",
    "     'ft1901_LL_vejle.txt',\n",
    "     'ft1901_LL_viborg.txt']\n",
    "\n",
    "    _path = '../../city_dump/data/utf8/'\n",
    "\n",
    "    df_list = []\n",
    "    for f in l:\n",
    "\n",
    "        print(f)\n",
    "        #Loading the data\n",
    "        df_list.append(get_df(_path+f))\n",
    "\n",
    "    #Concatenating all the files\n",
    "    df_list = pd.concat(df_list, sort=False)\n",
    "\n",
    "    #Saving the unique file\n",
    "    df_list.to_csv(_path+'ft1901_LL.txt', sep='$', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of files to work (with the 1901 collapsed)\n",
    "working_data = ['ft1845_LL.txt',\n",
    " 'ft1850_LL.txt',\n",
    " 'ft1860_LL.txt',\n",
    " 'ft1880_LL.txt',\n",
    " 'ft1885_LL.txt',\n",
    " 'ft1901_LL.txt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic matching\n",
    "(only performs the match if the names are identical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft1845_LL.txt\n",
      "1489875\n",
      "ft1850_LL.txt\n",
      "1391708\n",
      "ft1860_LL.txt\n",
      "1715906\n",
      "ft1880_LL.txt\n",
      "1967615\n",
      "ft1885_LL.txt\n",
      "327936\n",
      "ft1901_LL.txt\n",
      "1979025\n",
      "Done :D\n",
      "Matched records: 6256417 out of 8872065 ( 70.51816009012558 )%\n",
      "Matched places: 1577 out of 1924 ( 81.96465696465697 )%\n"
     ]
    }
   ],
   "source": [
    "_path = '../../city_dump/data/utf8/'\n",
    "\n",
    "#This is where I save the counts and then group it together\n",
    "out_list = []\n",
    "\n",
    "#where I save the missmatches and file year\n",
    "missmatches = []\n",
    "total_records = 0\n",
    "\n",
    "for f in working_data:\n",
    "    \n",
    "    print(f)\n",
    "    #Loading the data\n",
    "    df = get_df(_path+f)\n",
    "    \n",
    "    #Dropping empty rows due to the \"mal-conversion\" to utf8... The empty rows do contain data originally\n",
    "    #TODO: Fix the conversion thing (ask Barbara to provide me the UTF-8...)\n",
    "    df = df[~df.Herred.isna()]\n",
    "    print(len(df))\n",
    "    total_records = total_records + len(df)\n",
    "    \n",
    "    #Preforming the name cleaning for Sogne, Herred, and Amt\n",
    "    for working_column in ['Sogne','Herred','Amt']:\n",
    "        df[working_column] = df.apply(lambda x: name_cleaner(x), axis=1)\n",
    "\n",
    "    # Focusing on Sogn that match the Sogn list in DigDag\n",
    "    out = df.merge(dd[dd.art=='sogn'][['simplename', 'art', 'enhedid']], left_on='Sogne', right_on='simplename', how='left')\n",
    "\n",
    "    #keeping the missmatch\n",
    "    miss = out[out.art.isna()].drop_duplicates('Sogne', keep='first')\n",
    "    miss['year'] = f[2:6]\n",
    "    missmatches.append(miss)\n",
    "    \n",
    "    #Counting the matches\n",
    "    out = out[~out.art.isna()].groupby('enhedid').size().reset_index(name='counts')\n",
    "    \n",
    "    # setting the year\n",
    "    out['year'] = f[2:6]\n",
    "    \n",
    "    #Keeping the counts on RAM\n",
    "    out_list.append(out)\n",
    "    \n",
    "\n",
    "#Concatenating all the files (the counts and missmatches)\n",
    "out_list = pd.concat(out_list, sort=False)\n",
    "missmatches = pd.concat(missmatches, sort=False)\n",
    "\n",
    "#Saving the unique file in the HD\n",
    "out_list = out_list.merge(dd_org, on ='enhedid').pivot('enhedid', 'year', 'counts').fillna(0).astype(int)\n",
    "out_list.to_csv(_path+'../out/counts.txt', sep='$')\n",
    "out_list.to_csv(_path+'../out/places_FT_uniquevalues_01.tsv', sep='\\t')\n",
    "\n",
    "print('Done :D')\n",
    "\n",
    "nr_matched_records = out_list.sum().sum() #Two times sum, first one for year, and second one among years\n",
    "print('Matched records:',nr_matched_records, 'out of', total_records, '(', nr_matched_records/total_records*100,')%')\n",
    "print('Matched places:', len(out_list), 'out of', nr_sogn, '(', len(out_list)/nr_sogn*100,')%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1901</td>\n",
       "      <td>592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1885</td>\n",
       "      <td>556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1880</td>\n",
       "      <td>553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1845</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1860</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1850</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  counts\n",
       "5  1901     592\n",
       "4  1885     556\n",
       "3  1880     553\n",
       "0  1845     238\n",
       "2  1860     159\n",
       "1  1850     155"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cities that could not be matched on the first round counts per year\n",
    "missmatches.groupby('year').size().reset_index(name='counts').sort_values('counts', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing city similarity for missmatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 26428\n",
      "100 out of 26428\n",
      "200 out of 26428\n",
      "300 out of 26428\n",
      "400 out of 26428\n",
      "500 out of 26428\n",
      "600 out of 26428\n",
      "700 out of 26428\n",
      "800 out of 26428\n",
      "900 out of 26428\n",
      "1000 out of 26428\n",
      "1100 out of 26428\n",
      "1200 out of 26428\n",
      "1300 out of 26428\n",
      "1400 out of 26428\n",
      "1500 out of 26428\n",
      "1600 out of 26428\n",
      "1700 out of 26428\n",
      "1800 out of 26428\n",
      "1900 out of 26428\n",
      "2000 out of 26428\n",
      "2100 out of 26428\n",
      "2200 out of 26428\n",
      "2300 out of 26428\n",
      "2400 out of 26428\n",
      "2500 out of 26428\n",
      "2600 out of 26428\n",
      "2700 out of 26428\n",
      "2800 out of 26428\n",
      "2900 out of 26428\n",
      "3000 out of 26428\n",
      "3100 out of 26428\n",
      "3200 out of 26428\n",
      "3300 out of 26428\n",
      "3400 out of 26428\n",
      "3500 out of 26428\n",
      "3600 out of 26428\n",
      "3700 out of 26428\n",
      "3800 out of 26428\n",
      "3900 out of 26428\n",
      "4000 out of 26428\n",
      "4100 out of 26428\n",
      "4200 out of 26428\n",
      "4300 out of 26428\n",
      "4400 out of 26428\n",
      "4500 out of 26428\n",
      "4600 out of 26428\n",
      "4700 out of 26428\n",
      "4800 out of 26428\n",
      "4900 out of 26428\n",
      "5000 out of 26428\n",
      "5100 out of 26428\n",
      "5200 out of 26428\n",
      "5300 out of 26428\n",
      "5400 out of 26428\n",
      "5500 out of 26428\n",
      "5600 out of 26428\n",
      "5700 out of 26428\n",
      "5800 out of 26428\n",
      "5900 out of 26428\n",
      "6000 out of 26428\n",
      "6100 out of 26428\n",
      "6200 out of 26428\n",
      "6300 out of 26428\n",
      "6400 out of 26428\n",
      "6500 out of 26428\n",
      "6600 out of 26428\n",
      "6700 out of 26428\n",
      "6800 out of 26428\n",
      "6900 out of 26428\n",
      "7000 out of 26428\n",
      "7100 out of 26428\n",
      "7200 out of 26428\n",
      "7300 out of 26428\n",
      "7400 out of 26428\n",
      "7500 out of 26428\n",
      "7600 out of 26428\n",
      "7700 out of 26428\n",
      "7800 out of 26428\n",
      "7900 out of 26428\n",
      "8000 out of 26428\n",
      "8100 out of 26428\n",
      "8200 out of 26428\n",
      "8300 out of 26428\n",
      "8400 out of 26428\n",
      "8500 out of 26428\n",
      "8600 out of 26428\n",
      "8700 out of 26428\n",
      "8800 out of 26428\n",
      "8900 out of 26428\n",
      "9000 out of 26428\n",
      "9100 out of 26428\n",
      "9200 out of 26428\n",
      "9300 out of 26428\n",
      "9400 out of 26428\n",
      "9500 out of 26428\n",
      "9600 out of 26428\n",
      "9700 out of 26428\n",
      "9800 out of 26428\n",
      "9900 out of 26428\n",
      "10000 out of 26428\n",
      "10100 out of 26428\n",
      "10200 out of 26428\n",
      "10300 out of 26428\n",
      "10400 out of 26428\n",
      "10500 out of 26428\n",
      "10600 out of 26428\n",
      "10700 out of 26428\n",
      "10800 out of 26428\n",
      "10900 out of 26428\n",
      "11000 out of 26428\n",
      "11100 out of 26428\n",
      "11200 out of 26428\n",
      "11300 out of 26428\n",
      "11400 out of 26428\n",
      "11500 out of 26428\n",
      "11600 out of 26428\n",
      "11700 out of 26428\n",
      "11800 out of 26428\n",
      "11900 out of 26428\n",
      "12000 out of 26428\n",
      "12100 out of 26428\n",
      "12200 out of 26428\n",
      "12300 out of 26428\n",
      "12400 out of 26428\n",
      "12500 out of 26428\n",
      "12600 out of 26428\n",
      "12700 out of 26428\n",
      "12800 out of 26428\n",
      "12900 out of 26428\n",
      "13000 out of 26428\n",
      "13100 out of 26428\n",
      "13200 out of 26428\n",
      "13300 out of 26428\n",
      "13400 out of 26428\n",
      "13500 out of 26428\n",
      "13600 out of 26428\n",
      "13700 out of 26428\n",
      "13800 out of 26428\n",
      "13900 out of 26428\n",
      "14000 out of 26428\n",
      "14100 out of 26428\n",
      "14200 out of 26428\n",
      "14300 out of 26428\n",
      "14400 out of 26428\n",
      "14500 out of 26428\n",
      "14600 out of 26428\n",
      "14700 out of 26428\n",
      "14800 out of 26428\n",
      "14900 out of 26428\n",
      "15000 out of 26428\n",
      "15100 out of 26428\n",
      "15200 out of 26428\n",
      "15300 out of 26428\n",
      "15400 out of 26428\n",
      "15500 out of 26428\n",
      "15600 out of 26428\n",
      "15700 out of 26428\n",
      "15800 out of 26428\n",
      "15900 out of 26428\n",
      "16000 out of 26428\n",
      "16100 out of 26428\n",
      "16200 out of 26428\n",
      "16300 out of 26428\n",
      "16400 out of 26428\n",
      "16500 out of 26428\n",
      "16600 out of 26428\n",
      "16700 out of 26428\n",
      "16800 out of 26428\n",
      "16900 out of 26428\n",
      "17000 out of 26428\n",
      "17100 out of 26428\n",
      "17200 out of 26428\n",
      "17300 out of 26428\n",
      "17400 out of 26428\n",
      "17500 out of 26428\n",
      "17600 out of 26428\n",
      "17700 out of 26428\n",
      "17800 out of 26428\n",
      "17900 out of 26428\n",
      "18000 out of 26428\n",
      "18100 out of 26428\n",
      "18200 out of 26428\n",
      "18300 out of 26428\n",
      "18400 out of 26428\n",
      "18500 out of 26428\n",
      "18600 out of 26428\n",
      "18700 out of 26428\n",
      "18800 out of 26428\n",
      "18900 out of 26428\n",
      "19000 out of 26428\n",
      "19100 out of 26428\n",
      "19200 out of 26428\n",
      "19300 out of 26428\n",
      "19400 out of 26428\n",
      "19500 out of 26428\n",
      "19600 out of 26428\n",
      "19700 out of 26428\n",
      "19800 out of 26428\n",
      "19900 out of 26428\n",
      "20000 out of 26428\n",
      "20100 out of 26428\n",
      "20200 out of 26428\n",
      "20300 out of 26428\n",
      "20400 out of 26428\n",
      "20500 out of 26428\n",
      "20600 out of 26428\n",
      "20700 out of 26428\n",
      "20800 out of 26428\n",
      "20900 out of 26428\n",
      "21000 out of 26428\n",
      "21100 out of 26428\n",
      "21200 out of 26428\n",
      "21300 out of 26428\n",
      "21400 out of 26428\n",
      "21500 out of 26428\n",
      "21600 out of 26428\n",
      "21700 out of 26428\n",
      "21800 out of 26428\n",
      "21900 out of 26428\n",
      "22000 out of 26428\n",
      "22100 out of 26428\n",
      "22200 out of 26428\n",
      "22300 out of 26428\n",
      "22400 out of 26428\n",
      "22500 out of 26428\n",
      "22600 out of 26428\n",
      "22700 out of 26428\n",
      "22800 out of 26428\n",
      "22900 out of 26428\n",
      "23000 out of 26428\n",
      "23100 out of 26428\n",
      "23200 out of 26428\n",
      "23300 out of 26428\n",
      "23400 out of 26428\n",
      "23500 out of 26428\n",
      "23600 out of 26428\n",
      "23700 out of 26428\n",
      "23800 out of 26428\n",
      "23900 out of 26428\n",
      "24000 out of 26428\n",
      "24100 out of 26428\n",
      "24200 out of 26428\n",
      "24300 out of 26428\n",
      "24400 out of 26428\n",
      "24500 out of 26428\n",
      "24600 out of 26428\n",
      "24700 out of 26428\n",
      "24800 out of 26428\n",
      "24900 out of 26428\n",
      "25000 out of 26428\n",
      "25100 out of 26428\n",
      "25200 out of 26428\n",
      "25300 out of 26428\n",
      "25400 out of 26428\n",
      "25500 out of 26428\n",
      "25600 out of 26428\n",
      "25700 out of 26428\n",
      "25800 out of 26428\n",
      "25900 out of 26428\n",
      "26000 out of 26428\n",
      "26100 out of 26428\n",
      "26200 out of 26428\n",
      "26300 out of 26428\n",
      "26400 out of 26428\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nørre bramdrup</th>\n",
       "      <th>nørresundby landsogn</th>\n",
       "      <th>slagelse købstad</th>\n",
       "      <th>stillinge</th>\n",
       "      <th>allinge-sandvig købstæder</th>\n",
       "      <th>rønne købstad</th>\n",
       "      <th>aakirkeby købstad</th>\n",
       "      <th>hasle købstad</th>\n",
       "      <th>svaneke købstad</th>\n",
       "      <th>neksø købstad</th>\n",
       "      <th>...</th>\n",
       "      <th>bernhardsvej</th>\n",
       "      <th>baunegaardsvej</th>\n",
       "      <th>bengtasvej</th>\n",
       "      <th>bogholder alle</th>\n",
       "      <th>boyesgade</th>\n",
       "      <th>broagergade</th>\n",
       "      <th>birkegade</th>\n",
       "      <th>rugaards landevej</th>\n",
       "      <th>esbjerg købstad</th>\n",
       "      <th>silkeborg købstad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kronborg</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>præstø</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bornholms</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svendborg</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ålborg</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1237 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           nørre bramdrup  nørresundby landsogn  slagelse købstad  stillinge  \\\n",
       "kronborg             0.43                  0.40              0.40       0.49   \n",
       "præstø               0.41                  0.48              0.41       0.52   \n",
       "bornholms            0.40                  0.38              0.45       0.31   \n",
       "svendborg            0.41                  0.47              0.50       0.60   \n",
       "ålborg               0.41                  0.41              0.49       0.52   \n",
       "\n",
       "           allinge-sandvig købstæder  rønne købstad  aakirkeby købstad  \\\n",
       "kronborg                        0.44           0.54               0.52   \n",
       "præstø                          0.00           0.50               0.41   \n",
       "bornholms                       0.37           0.52               0.39   \n",
       "svendborg                       0.37           0.41               0.39   \n",
       "ålborg                          0.47           0.00               0.41   \n",
       "\n",
       "           hasle købstad  svaneke købstad  neksø købstad  ...  bernhardsvej  \\\n",
       "kronborg            0.40             0.40           0.42  ...          0.53   \n",
       "præstø              0.50             0.41           0.50  ...          0.42   \n",
       "bornholms           0.52             0.45           0.46  ...          0.69   \n",
       "svendborg           0.52             0.59           0.50  ...          0.51   \n",
       "ålborg              0.41             0.00           0.00  ...          0.50   \n",
       "\n",
       "           baunegaardsvej  bengtasvej  bogholder alle  boyesgade  broagergade  \\\n",
       "kronborg             0.43        0.45            0.51       0.46         0.56   \n",
       "præstø               0.00        0.34            0.00       0.43         0.42   \n",
       "bornholms            0.56        0.59            0.71       0.64         0.48   \n",
       "svendborg            0.41        0.47            0.40       0.46         0.44   \n",
       "ålborg               0.49        0.51            0.57       0.61         0.59   \n",
       "\n",
       "           birkegade  rugaards landevej  esbjerg købstad  silkeborg købstad  \n",
       "kronborg        0.56               0.46             0.41               0.57  \n",
       "præstø          0.43               0.41             0.41               0.41  \n",
       "bornholms       0.53               0.39             0.51               0.28  \n",
       "svendborg       0.44               0.28             0.56               0.71  \n",
       "ålborg          0.61               0.32             0.57               0.71  \n",
       "\n",
       "[5 rows x 1237 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the potential first matches\n",
    "\n",
    "mm = missmatches.Sogne.unique()\n",
    "sn = dd.simplename.unique()\n",
    "\n",
    "distance_jaro = np.zeros((len(sn),len(mm)))\n",
    "distance_leven = np.zeros((len(sn),len(mm)))\n",
    "\n",
    "for i in range(len(sn)):\n",
    "    if i%100 == 0: print(i, 'out of' ,len(sn))\n",
    "        \n",
    "    for j in range(len(mm)):\n",
    "        #If variable is none skip\n",
    "        if not mm[j]: continue\n",
    "        \n",
    "        #This matrix is not simetric because x and y axis are not the same!\n",
    "        try:\n",
    "            distance_jaro[i][j] = distance.get_jaro_distance(sn[i],mm[j])\n",
    "            distance_leven[i][j] = Levenshtein.distance(sn[i],mm[j])/(len(sn[i])+len(mm[j]))\n",
    "        except:\n",
    "            print('Could not make it',i,j)\n",
    "            print(sn[i],mm[j])\n",
    "        \n",
    "#Index is the reference names found in the data, columns to the digdag\n",
    "distance_jaro = pd.DataFrame(data = distance_jaro, columns = mm, index = sn)\n",
    "distance_leven = pd.DataFrame(data = distance_leven, columns = mm, index = sn)\n",
    "distance_jaro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_name</th>\n",
       "      <th>potential_match</th>\n",
       "      <th>jaro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nørre bramdrup</td>\n",
       "      <td>nørre asmindrup</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nørresundby landsogn</td>\n",
       "      <td>nørresnedebylandsogn</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>slagelse købstad</td>\n",
       "      <td>slagelse købstad</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stillinge</td>\n",
       "      <td>stilling</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allinge-sandvig købstæder</td>\n",
       "      <td>allinge-sandvig købstæder</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   data_name            potential_match  jaro\n",
       "0             nørre bramdrup            nørre asmindrup  0.90\n",
       "1       nørresundby landsogn       nørresnedebylandsogn  0.96\n",
       "2           slagelse købstad           slagelse købstad  1.00\n",
       "3                  stillinge                   stilling  0.98\n",
       "4  allinge-sandvig købstæder  allinge-sandvig købstæder  1.00"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the best possible match (left=name found in the data, right=name found in the extended version of digdag)\n",
    "a = distance_jaro.idxmax().reset_index(name = 'potential_match')\n",
    "b = distance_jaro.max().reset_index(name='jaro')\n",
    "c = a.merge(b, on='index').rename(columns={'index':'data_name'})\n",
    "c.to_csv(_path+'../out/mapping.tsv', sep='\\t')\n",
    "c.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced matching\n",
    "(This is the same as the basic matching but in this case it matches to the computed best match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>mapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nørre bramdrup</td>\n",
       "      <td>nørre asmindrup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nørresundby landsogn</td>\n",
       "      <td>nørresnedebylandsogn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>slagelse købstad</td>\n",
       "      <td>slagelse købstad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stillinge</td>\n",
       "      <td>stilling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allinge-sandvig købstæder</td>\n",
       "      <td>allinge-sandvig købstæder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    original                     mapped\n",
       "0             nørre bramdrup            nørre asmindrup\n",
       "1       nørresundby landsogn       nørresnedebylandsogn\n",
       "2           slagelse købstad           slagelse købstad\n",
       "3                  stillinge                   stilling\n",
       "4  allinge-sandvig købstæder  allinge-sandvig købstæder"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select threshold to perform the matching, each mapping contains only the best jaro\n",
    "THRESHOLD = 0.9\n",
    "\n",
    "dfmap = pd.read_csv(_path+'../out/mapping.tsv', sep = '\\t', dtype=str, names=['original','mapped', 'score'], skiprows=1)\n",
    "dfmap = dfmap[dfmap.score.astype(float) >= THRESHOLD][['original','mapped']]\n",
    "dfmap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft1845_LL.txt\n",
      "1489875\n",
      "ft1850_LL.txt\n",
      "1391708\n",
      "ft1860_LL.txt\n",
      "1715906\n",
      "ft1880_LL.txt\n",
      "1967615\n",
      "ft1885_LL.txt\n",
      "327936\n",
      "ft1901_LL.txt\n",
      "1979025\n",
      "Done :D\n",
      "Matched records: 6674325 out of 8872065 ( 75.22854036799775 )%\n",
      "Matched places: 1647 out of 1924 ( 85.6029106029106 )%\n"
     ]
    }
   ],
   "source": [
    "_path = '../../city_dump/data/utf8/'\n",
    "\n",
    "#This is where I save the counts and then group it together\n",
    "out_list = []\n",
    "\n",
    "\n",
    "for f in working_data:\n",
    "    \n",
    "    print(f)\n",
    "    #Loading the data\n",
    "    df = get_df(_path+f)\n",
    "    \n",
    "    #Dropping empty rows due to the \"mal-conversion\" to utf8... The empty rows do contain data originally\n",
    "    #TODO: Fix the conversion thing\n",
    "    df = df[~df.Herred.isna()]\n",
    "    print(len(df))\n",
    "    \n",
    "    #Preforming the name cleaning for Sogne, Herred, and Amt\n",
    "    for working_column in ['Sogne','Herred','Amt']:\n",
    "        df[working_column] = df.apply(lambda x: name_cleaner(x), axis=1)\n",
    "    \n",
    "    #Performing the matching for \"inexisting places\"\n",
    "    df = df.merge(dfmap, left_on='Sogne', right_on='original', how='left')\n",
    "    df.loc[~df.mapped.isna(), 'Sogne'] = df.loc[~df.mapped.isna(), 'mapped']\n",
    "\n",
    "\n",
    "    # Focusing on Sogn that match the Sogn list in DigDag\n",
    "    out = df.merge(dd[dd.art=='sogn'][['simplename', 'art','enhedid']], left_on='Sogne', right_on='simplename', how='left')\n",
    "    \n",
    "    #Counting the matches\n",
    "    out = out[~out.art.isna()].groupby('enhedid').size().reset_index(name='counts')\n",
    "    \n",
    "    # setting the year\n",
    "    out['year'] = f[2:6]\n",
    "    \n",
    "    #Keeping the counts on RAM\n",
    "    out_list.append(out)\n",
    "\n",
    "    \n",
    "#Concatenating all the files (the counts and missmatches)\n",
    "out_list = pd.concat(out_list, sort=False)\n",
    "\n",
    "\n",
    "#Saving the unique file in the HD\n",
    "out_list = out_list.merge(dd_org, on ='enhedid').pivot('simplename', 'year', 'counts').fillna(0).astype(int)\n",
    "out_list.to_csv(_path+'../out/counts_first_jaro.txt', sep='$')\n",
    "out_list.to_csv(_path+'../out/places_FT_jaro0.9_01.tsv', sep='\\t')\n",
    "\n",
    "\n",
    "print('Done :D')\n",
    "\n",
    "nr_matched_records = out_list.sum().sum() #Two times sum, first one for year, and second one among years\n",
    "print('Matched records:',nr_matched_records, 'out of', total_records, '(', nr_matched_records/total_records*100,')%')\n",
    "print('Matched places:', len(out_list), 'out of', nr_sogn, '(', len(out_list)/nr_sogn*100,')%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 out of 1237\n",
      "200 out of 1237\n",
      "300 out of 1237\n",
      "400 out of 1237\n",
      "500 out of 1237\n",
      "600 out of 1237\n",
      "700 out of 1237\n",
      "800 out of 1237\n",
      "900 out of 1237\n",
      "1000 out of 1237\n",
      "1100 out of 1237\n",
      "1200 out of 1237\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>potential_match</th>\n",
       "      <th>score</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nørre asmindrup</td>\n",
       "      <td>0.90</td>\n",
       "      <td>nørre bramdrup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nørre rangstrup</td>\n",
       "      <td>0.90</td>\n",
       "      <td>nørre bramdrup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nørre tranders</td>\n",
       "      <td>0.89</td>\n",
       "      <td>nørre bramdrup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nørre tyrstrup</td>\n",
       "      <td>0.89</td>\n",
       "      <td>nørre bramdrup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nørrerangstrup</td>\n",
       "      <td>0.89</td>\n",
       "      <td>nørre bramdrup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nørre højrup</td>\n",
       "      <td>0.88</td>\n",
       "      <td>nørre bramdrup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nørreasmindrup</td>\n",
       "      <td>0.88</td>\n",
       "      <td>nørre bramdrup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nørre dalby</td>\n",
       "      <td>0.87</td>\n",
       "      <td>nørre bramdrup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nørre bork</td>\n",
       "      <td>0.87</td>\n",
       "      <td>nørre bramdrup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nørre</td>\n",
       "      <td>0.87</td>\n",
       "      <td>nørre bramdrup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nørresnedebylandsogn</td>\n",
       "      <td>0.96</td>\n",
       "      <td>nørresundby landsogn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nørresnedelandsogn</td>\n",
       "      <td>0.94</td>\n",
       "      <td>nørresundby landsogn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>nørrelands bylandsogn</td>\n",
       "      <td>0.94</td>\n",
       "      <td>nørresundby landsogn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nørre snede bylandsogn</td>\n",
       "      <td>0.93</td>\n",
       "      <td>nørresundby landsogn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nørrelandsbylandsogn</td>\n",
       "      <td>0.93</td>\n",
       "      <td>nørresundby landsogn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           potential_match  score              original\n",
       "0          nørre asmindrup   0.90        nørre bramdrup\n",
       "1          nørre rangstrup   0.90        nørre bramdrup\n",
       "2           nørre tranders   0.89        nørre bramdrup\n",
       "3           nørre tyrstrup   0.89        nørre bramdrup\n",
       "4           nørrerangstrup   0.89        nørre bramdrup\n",
       "5             nørre højrup   0.88        nørre bramdrup\n",
       "6           nørreasmindrup   0.88        nørre bramdrup\n",
       "7              nørre dalby   0.87        nørre bramdrup\n",
       "8               nørre bork   0.87        nørre bramdrup\n",
       "9                    nørre   0.87        nørre bramdrup\n",
       "10    nørresnedebylandsogn   0.96  nørresundby landsogn\n",
       "11      nørresnedelandsogn   0.94  nørresundby landsogn\n",
       "12   nørrelands bylandsogn   0.94  nørresundby landsogn\n",
       "13  nørre snede bylandsogn   0.93  nørresundby landsogn\n",
       "14    nørrelandsbylandsogn   0.93  nørresundby landsogn"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the best possible matches\n",
    "\n",
    "concatenate = []\n",
    "i=0\n",
    "for col in distance_jaro.columns:\n",
    "    i = i+1\n",
    "    if i % 100 == 0: print(i, 'out of', len(distance_jaro.columns))\n",
    "    aux = distance_jaro.nlargest(10, col)[[col]]\n",
    "    aux.columns = ['score']\n",
    "    aux['original'] = col\n",
    "    concatenate.append(aux)\n",
    "\n",
    "concatenate = pd.concat(concatenate, sort=False)\n",
    "concatenate = concatenate.reset_index()\n",
    "concatenate.columns = ['potential_match','score','original']\n",
    "concatenate[['original','potential_match','score']][~concatenate.original.isin(concatenate[concatenate.score >= 0.9].original.unique())].to_csv(_path+'../out/places_possible_matches_jaro_01.tsv', index=False, sep='\\t')\n",
    "concatenate.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
