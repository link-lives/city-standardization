{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries for data management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Importing libraries for system management\n",
    "import os\n",
    "\n",
    "#Distance computation\n",
    "from pyjarowinkler import distance\n",
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Check if Danish computers have the same problem...\n",
    "I_want_to_run_all_the_preprocessing = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the current format (ISO-8859-14) into UTF-8 \n",
    "iconv -f ISO-8859-14 file_in.csv > file_out.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if I_want_to_run_all_the_preprocessing:\n",
    "    \n",
    "    #Copying into a new directory\n",
    "    ! cp -R ../../city_dump/data/LL/ ../../city_dump/data/utf8/\n",
    "\n",
    "    #Getting all files\n",
    "    d_path = '../../city_dump/data/utf8/'\n",
    "    l = next(os.walk(d_path))[2]\n",
    "\n",
    "    #Converting the files to utf8 (not sure this will work in computers different than mac...)\n",
    "    for file in l:\n",
    "        f_path = d_path+file\n",
    "        tmp_path = d_path+'tmp.csv'\n",
    "        ! iconv -f ISO-8859-14 $f_path > $tmp_path\n",
    "        !mv $tmp_path $f_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading DigDag\n",
    "and transforming it so I encode as many logical variation of the names as possible. In this way the variations for each place is only appied once whereas if we do the same for the data it will need to be applied to each place taking much longer. But the way to remember the original variation is to keep the \"enhedid\", which is the reference id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function adds extra rows in the dataframe *dd* for the \n",
    "# places where *word* exists and replaces it with *replacement*\n",
    "def adding_extra_rows(dd, word, replacement):\n",
    "    dd['special'] = dd['simplename'].apply(lambda x: word in x) \n",
    "    dd['simplename2'] = dd.simplename.apply(lambda x: x.replace(word,replacement))\n",
    "    return pd.concat([dd[['navn', 'enhedid', 'enhedtype', 'art', 'simplename']],dd[dd['special']][['navn', 'enhedid', 'enhedtype', 'art', 'simplename2']].rename(columns={'simplename2':'simplename'})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>navn</th>\n",
       "      <th>enhedid</th>\n",
       "      <th>enhedtype</th>\n",
       "      <th>art</th>\n",
       "      <th>simplename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kronborg Amt</td>\n",
       "      <td>118765</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>kronborg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Præstø Amt</td>\n",
       "      <td>118791</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>præstø</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bornholms Amt</td>\n",
       "      <td>118792</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>bornholms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Svendborg Amt</td>\n",
       "      <td>118813</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>svendborg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ålborg Amt</td>\n",
       "      <td>118819</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>ålborg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sorø Amt</td>\n",
       "      <td>118785</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>sorø</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Århus Amt</td>\n",
       "      <td>118846</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>århus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hjørring Amt</td>\n",
       "      <td>118820</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>hjørring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bøvling Amt</td>\n",
       "      <td>118851</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>bøvling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vejle Amt</td>\n",
       "      <td>118849</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>vejle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dueholm Amt</td>\n",
       "      <td>118821</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>dueholm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ørum Amt</td>\n",
       "      <td>118824</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>ørum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Thisted Amt</td>\n",
       "      <td>118826</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>thisted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Viborg Amt</td>\n",
       "      <td>118830</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>viborg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ringkøbing Amt</td>\n",
       "      <td>118853</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>ringkøbing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Københavns Kommune</td>\n",
       "      <td>370923</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>københavns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Frederiksberg Kommune</td>\n",
       "      <td>370924</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>frederiksberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fyns Amt</td>\n",
       "      <td>118739</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>fyns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sæbygård Amt</td>\n",
       "      <td>118773</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>sæbygård</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ribe Amt</td>\n",
       "      <td>118855</td>\n",
       "      <td>11</td>\n",
       "      <td>amt</td>\n",
       "      <td>ribe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     navn enhedid enhedtype  art     simplename\n",
       "0            Kronborg Amt  118765        11  amt       kronborg\n",
       "1              Præstø Amt  118791        11  amt         præstø\n",
       "2           Bornholms Amt  118792        11  amt      bornholms\n",
       "3           Svendborg Amt  118813        11  amt      svendborg\n",
       "4              Ålborg Amt  118819        11  amt         ålborg\n",
       "5                Sorø Amt  118785        11  amt           sorø\n",
       "6               Århus Amt  118846        11  amt          århus\n",
       "7            Hjørring Amt  118820        11  amt       hjørring\n",
       "8             Bøvling Amt  118851        11  amt        bøvling\n",
       "9               Vejle Amt  118849        11  amt          vejle\n",
       "10            Dueholm Amt  118821        11  amt        dueholm\n",
       "11               Ørum Amt  118824        11  amt           ørum\n",
       "12            Thisted Amt  118826        11  amt        thisted\n",
       "13             Viborg Amt  118830        11  amt         viborg\n",
       "14         Ringkøbing Amt  118853        11  amt     ringkøbing\n",
       "15     Københavns Kommune  370923        11  amt     københavns\n",
       "16  Frederiksberg Kommune  370924        11  amt  frederiksberg\n",
       "17               Fyns Amt  118739        11  amt           fyns\n",
       "18           Sæbygård Amt  118773        11  amt       sæbygård\n",
       "19               Ribe Amt  118855        11  amt           ribe"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The digdag seems to have duplicates which I do not understand why\n",
    "dd = pd.read_csv('../../city_dump/data/rl_places_digdag_v1.txt', sep = '\\t', encoding='utf-16', dtype=str)\n",
    "dd_org = dd.copy()\n",
    "\n",
    "#Getting the Købstad and putting it to the original data\n",
    "dd2 = pd.read_csv('../../city_dump/data/koebstad.csv', sep = ';', encoding='utf-8', dtype=str)\n",
    "dd2['enhedtype'] = dd2['art'] \n",
    "dd = pd.concat([dd, dd2[~dd2.isna()][['navn','enhedid','enhedtype','art','simplename']]])\n",
    "dd['simplename'] = dd['simplename'].astype(str)\n",
    "\n",
    "\n",
    "#Moving the Købstad to the right column\n",
    "dd['art'] = np.where(dd['enhedtype'] == 'Købstad', ['Købstadskommune']*len(dd), dd['art'])\n",
    "\n",
    "#adding a conversion of special characters to latin letters (å -> aa, ø -> oe, æ -> ae) and adding them to the reference list\n",
    "dd = adding_extra_rows(dd, 'å', 'aa')\n",
    "dd = adding_extra_rows(dd, 'ø', 'oe')\n",
    "dd = adding_extra_rows(dd, 'æ', 'ae')\n",
    "\n",
    "#Preparing the names to append them at the simple name\n",
    "dd['art'] = dd['art'].apply({'Amt':'amt', 'Sogn':'sogn','Købstadskommune':'købstad', 'Geografisk Herred':'herred', 'Processing':''}.get)\n",
    "\n",
    "#Adding a duplicated list of their unit type to increase matches\n",
    "dd['simplename2'] = dd.apply(lambda row: str(row['simplename'])+' '+str(row['art']), axis=1)\n",
    "dd = pd.concat([dd[['navn', 'enhedid', 'enhedtype', 'art', 'simplename']],dd[['navn', 'enhedid', 'enhedtype', 'art', 'simplename2']].rename(columns={'simplename2':'simplename'})])\n",
    "\n",
    "#Adding the plural købstæder as well\n",
    "dd = adding_extra_rows(dd, 'købstad', 'købstæder')\n",
    "\n",
    "#Adding spaces instead of hyphens (new rows)\n",
    "dd = adding_extra_rows(dd, '-', ' ')\n",
    "\n",
    "#Removing spaces (new rows)\n",
    "dd = adding_extra_rows(dd, ' ', '')\n",
    "\n",
    "#Adding bysogn and landsogn (new rows)\n",
    "dd = adding_extra_rows(dd, 'sogn', 'bysogn')\n",
    "dd = adding_extra_rows(dd, 'sogn', 'landsogn')\n",
    "\n",
    "#adding rows where the last letter's \"e\" will be removed\n",
    "dd['special'] = dd['simplename'].str[-1] == 'e'\n",
    "dd['simplename2'] = dd['simplename'].str[:-1]\n",
    "dd = pd.concat([dd[['navn', 'enhedid', 'enhedtype', 'art', 'simplename']],dd[dd['special']][['navn', 'enhedid', 'enhedtype', 'art', 'simplename2']].rename(columns={'simplename2':'simplename'})])\n",
    "\n",
    "#Dropping duplicates from digdag\n",
    "#print(dd[dd.duplicated('simplename', keep=False)].sort_values('simplename').head(30))\n",
    "dd.drop_duplicates(['art','simplename'], keep='first', inplace=True)\n",
    "\n",
    "#Drop 'Non' from the list, this may be one of my artifacts...\n",
    "dd = dd[(dd.simplename.apply(lambda x: not 'Non' in x))]\n",
    "\n",
    "# TODO take into consideration that the same city name can be in varios geographical areas...\n",
    "# It should be matched with herred to increase accuracy for each record. However, right now we're only cleaning\n",
    "# not sure how pressing the issue is...\n",
    "nr_sogn = len(dd_org[dd_org.art=='Sogn'].simplename.unique()) \n",
    "dd.head(20)\n",
    "\n",
    "#TODO: Right now I can map things to amt for example which should not be the case...\n",
    "#dd =dd[dd.art='sogn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length original:\t 2519 \n",
      "length modified:\t 27097 \n",
      "unique sogn keys:\t 1924\n"
     ]
    }
   ],
   "source": [
    "print('length original:\\t', len(dd_org), '\\nlength modified:\\t', len(dd), '\\nunique sogn keys:\\t', nr_sogn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the df from the $ separated file (for some reason pandas has problems with random lines)\n",
    "def get_df(f_path):\n",
    "    r= []\n",
    "    columns = []\n",
    "    with open(f_path) as f:\n",
    "        first = True\n",
    "        for line in f:\n",
    "            line = line.rstrip().split('$')\n",
    "            if first:\n",
    "                length = len(line)\n",
    "                columns = line\n",
    "                first=False\n",
    "            else:\n",
    "                r.append(line[:length])\n",
    "                \n",
    "    return pd.DataFrame(data=r, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name cleaning function\n",
    "def name_cleaner(s, working_column):\n",
    "    try:\n",
    "        o =s[working_column].lower().rstrip().replace('  ', ' ')#.replace(' købstad', '')\n",
    "        if ' (' in o: return o.split(' (')[0]\n",
    "        return o\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping all 1901 files together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if I_want_to_run_all_the_preprocessing:\n",
    "    \n",
    "    l =['ft1901_LL_aalborg.txt',\n",
    "     'ft1901_LL_aarhus.txt',\n",
    "     'ft1901_LL_bornholm.txt',\n",
    "     'ft1901_LL_frederiksborg.txt',\n",
    "     'ft1901_LL_hjoerring.txt',\n",
    "     'ft1901_LL_holbaek.txt',\n",
    "     'ft1901_LL_kbhv.txt',\n",
    "     'ft1901_LL_maribo.txt',\n",
    "     'ft1901_LL_odense.txt',\n",
    "     'ft1901_LL_praestoe.txt',\n",
    "     'ft1901_LL_randers.txt',\n",
    "     'ft1901_LL_ribe.txt',\n",
    "     'ft1901_LL_ringkoebing.txt',\n",
    "     'ft1901_LL_roskilde.txt',\n",
    "     'ft1901_LL_skanderborg.txt',\n",
    "     'ft1901_LL_soroe.txt',\n",
    "     'ft1901_LL_svendborg.txt',\n",
    "     'ft1901_LL_thisted.txt',\n",
    "     'ft1901_LL_vejle.txt',\n",
    "     'ft1901_LL_viborg.txt']\n",
    "\n",
    "    _path = '../../city_dump/data/utf8/'\n",
    "\n",
    "    df_list = []\n",
    "    for f in l:\n",
    "\n",
    "        print(f)\n",
    "        #Loading the data\n",
    "        df_list.append(get_df(_path+f))\n",
    "\n",
    "    #Concatenating all the files\n",
    "    df_list = pd.concat(df_list, sort=False)\n",
    "\n",
    "    #Saving the unique file\n",
    "    df_list.to_csv(_path+'ft1901_LL.txt', sep='$', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of files to work (with the 1901 collapsed)\n",
    "working_data = ['ft1845_LL.txt',\n",
    " 'ft1850_LL.txt',\n",
    " 'ft1860_LL.txt',\n",
    " 'ft1880_LL.txt',\n",
    " 'ft1885_LL.txt',\n",
    " 'ft1901_LL.txt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data and counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft1845_LL.txt\n",
      "1489875\n",
      "ft1850_LL.txt\n",
      "1391708\n",
      "ft1860_LL.txt\n",
      "1715906\n",
      "ft1880_LL.txt\n",
      "1967615\n",
      "ft1885_LL.txt\n",
      "327936\n",
      "ft1901_LL.txt\n",
      "1979025\n",
      "Done! :D\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sogne_data</th>\n",
       "      <th>counts</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aabenraa landsogn</td>\n",
       "      <td>444</td>\n",
       "      <td>1845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaby</td>\n",
       "      <td>1520</td>\n",
       "      <td>1845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aadum</td>\n",
       "      <td>554</td>\n",
       "      <td>1845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aagerup</td>\n",
       "      <td>1046</td>\n",
       "      <td>1845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sogne_data  counts  year\n",
       "0                          1  1845\n",
       "1  aabenraa landsogn     444  1845\n",
       "2               aaby    1520  1845\n",
       "3              aadum     554  1845\n",
       "4            aagerup    1046  1845"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_path = '../../city_dump/data/utf8/'\n",
    "\n",
    "#This is where I save the counts and then group it together\n",
    "out_list = []\n",
    "\n",
    "#where I save the missmatches and file year\n",
    "missmatches = []\n",
    "total_records = 0\n",
    "\n",
    "for f in working_data:\n",
    "    \n",
    "    print(f)\n",
    "    #Loading the data\n",
    "    df = get_df(_path+f)\n",
    "    \n",
    "    #Dropping empty rows due to the \"mal-conversion\" to utf8... The empty rows do contain data originally\n",
    "    #TODO: Fix the conversion thing (ask Barbara to provide me the UTF-8...)\n",
    "    df = df[~df.Herred.isna()]\n",
    "    print(len(df))\n",
    "    total_records = total_records + len(df)\n",
    "    \n",
    "    #Preforming the name cleaning for Sogne, Herred, and Amt\n",
    "    for working_column in ['Sogne','Herred','Amt']:\n",
    "        df[working_column+'_data'] = df.apply(lambda x: name_cleaner(x, working_column), axis=1)\n",
    "    \n",
    "    #Reducing Dimensionality and saving in RAM\n",
    "    out = df.groupby('Sogne_data').size().reset_index(name = 'counts')\n",
    "    out['year'] = f[2:6]\n",
    "    out_list.append(out)\n",
    "    \n",
    "out_list = pd.concat(out_list, sort=False)\n",
    "print('Done! :D')\n",
    "\n",
    "out_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sogne_data</th>\n",
       "      <th>1845</th>\n",
       "      <th>1850</th>\n",
       "      <th>1860</th>\n",
       "      <th>1880</th>\n",
       "      <th>1885</th>\n",
       "      <th>1901</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(h. c.) andersensvej</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>744</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a. f. beyersvej</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a. n. hansens allé</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aabenraa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1404</td>\n",
       "      <td>1314</td>\n",
       "      <td>1044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Sogne_data 1845 1850 1860  1880  1885  1901\n",
       "0                          1    0    0     0     0     0\n",
       "1  (h. c.) andersensvej    0    0    0   744     0     0\n",
       "2       a. f. beyersvej    0    0    0     0     0    78\n",
       "3    a. n. hansens allé    0    0    0     0     0    10\n",
       "4              aabenraa    0    0    0  1404  1314  1044"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Putting it nicely, on a more horitzontal table\n",
    "out_list = out_list.pivot('Sogne_data', 'year', 'counts').fillna(0).astype(int).reset_index().reset_index(drop=True)\n",
    "out_list = pd.DataFrame(out_list.values, columns=out_list.columns.tolist()) #Getting rid of the wrong index\n",
    "out_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic matching\n",
    "(only performs the match if the names are identical)\n",
    "\n",
    "_This could be done only once by countring reference id and year. Then with the names we can keep constraining with matches_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1741\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>navn</th>\n",
       "      <th>enhedid</th>\n",
       "      <th>art</th>\n",
       "      <th>1845</th>\n",
       "      <th>1850</th>\n",
       "      <th>1860</th>\n",
       "      <th>1880</th>\n",
       "      <th>1885</th>\n",
       "      <th>1901</th>\n",
       "      <th>extended_digdag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aabenraa Sogn</td>\n",
       "      <td>113932</td>\n",
       "      <td>sogn</td>\n",
       "      <td>444</td>\n",
       "      <td>0</td>\n",
       "      <td>650</td>\n",
       "      <td>1404</td>\n",
       "      <td>1314</td>\n",
       "      <td>1044</td>\n",
       "      <td>{aabenraa, aabenraa landsogn}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aaker Sogn</td>\n",
       "      <td>115247</td>\n",
       "      <td>sogn</td>\n",
       "      <td>1864</td>\n",
       "      <td>1956</td>\n",
       "      <td>1978</td>\n",
       "      <td>2485</td>\n",
       "      <td>0</td>\n",
       "      <td>2421</td>\n",
       "      <td>{aaker}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aal Sogn</td>\n",
       "      <td>115248</td>\n",
       "      <td>sogn</td>\n",
       "      <td>917</td>\n",
       "      <td>972</td>\n",
       "      <td>962</td>\n",
       "      <td>1097</td>\n",
       "      <td>0</td>\n",
       "      <td>1299</td>\n",
       "      <td>{aal}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aarestrup Sogn</td>\n",
       "      <td>115255</td>\n",
       "      <td>sogn</td>\n",
       "      <td>468</td>\n",
       "      <td>523</td>\n",
       "      <td>611</td>\n",
       "      <td>773</td>\n",
       "      <td>0</td>\n",
       "      <td>844</td>\n",
       "      <td>{aarestrup}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abild Sogn</td>\n",
       "      <td>113795</td>\n",
       "      <td>sogn</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{abild}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             navn enhedid   art  1845  1850  1860  1880  1885  1901  \\\n",
       "0   Aabenraa Sogn  113932  sogn   444     0   650  1404  1314  1044   \n",
       "1      Aaker Sogn  115247  sogn  1864  1956  1978  2485     0  2421   \n",
       "2        Aal Sogn  115248  sogn   917   972   962  1097     0  1299   \n",
       "3  Aarestrup Sogn  115255  sogn   468   523   611   773     0   844   \n",
       "4      Abild Sogn  113795  sogn    90     0  1165     0     0     0   \n",
       "\n",
       "                 extended_digdag  \n",
       "0  {aabenraa, aabenraa landsogn}  \n",
       "1                        {aaker}  \n",
       "2                          {aal}  \n",
       "3                    {aarestrup}  \n",
       "4                        {abild}  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Notice that I only match for Sogn\n",
    "out = out_list.merge(dd[['navn','simplename', 'art', 'enhedid']], left_on='Sogne_data', right_on='simplename', how='left')\n",
    "\n",
    "#Those are the missmatch\n",
    "miss = out[out.enhedid.isna()]\n",
    "miss.head()\n",
    "\n",
    "#Here are the match\n",
    "match = out[~out.enhedid.isna()]\n",
    "match.head()\n",
    "\n",
    "# Aggregating the match by enhedid and year\n",
    "agg_counts = match.groupby(['navn', 'enhedid', 'art'],as_index = False).agg({'1845':'sum', '1850':'sum','1860':'sum', '1880':'sum','1885':'sum', '1901':'sum'})\n",
    "\n",
    "# Grouping all enhedid to see how many different versions of the same Sogne we have in the data\n",
    "diff_counts = match.groupby(['navn','enhedid'])['Sogne_data'].apply(set).reset_index(name='extended_digdag') #if parenthesis is confusing add **.apply(lambda x: ', '.join(x))** before the reset index\n",
    "\n",
    "# Joining DFs and saving\n",
    "s = agg_counts.merge(diff_counts, on = ['navn','enhedid'])\n",
    "s.to_csv(_path+'../out/places_FT_uniquevalues_01.tsv', sep='\\t', index=False)\n",
    "print(len(s))\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Compute measure metrics\n",
    "#Something like\n",
    "'''\n",
    "print('Matched records:',nr_matched_records, 'out of', total_records, '(', nr_matched_records/total_records*100,')%')\n",
    "print('Matched places:', len(out_list), 'out of', nr_sogn, '(', len(out_list)/nr_sogn*100,')%')\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Jaro distances for missmatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 26784\n",
      "100 out of 26784\n",
      "200 out of 26784\n",
      "300 out of 26784\n",
      "400 out of 26784\n",
      "500 out of 26784\n",
      "600 out of 26784\n",
      "700 out of 26784\n",
      "800 out of 26784\n",
      "900 out of 26784\n",
      "1000 out of 26784\n",
      "1100 out of 26784\n",
      "1200 out of 26784\n",
      "1300 out of 26784\n",
      "1400 out of 26784\n",
      "1500 out of 26784\n",
      "1600 out of 26784\n",
      "1700 out of 26784\n",
      "1800 out of 26784\n",
      "1900 out of 26784\n",
      "2000 out of 26784\n",
      "2100 out of 26784\n",
      "2200 out of 26784\n",
      "2300 out of 26784\n",
      "2400 out of 26784\n",
      "2500 out of 26784\n",
      "2600 out of 26784\n",
      "2700 out of 26784\n",
      "2800 out of 26784\n",
      "2900 out of 26784\n",
      "3000 out of 26784\n",
      "3100 out of 26784\n",
      "3200 out of 26784\n",
      "3300 out of 26784\n",
      "3400 out of 26784\n",
      "3500 out of 26784\n",
      "3600 out of 26784\n",
      "3700 out of 26784\n",
      "3800 out of 26784\n",
      "3900 out of 26784\n",
      "4000 out of 26784\n",
      "4100 out of 26784\n",
      "4200 out of 26784\n",
      "4300 out of 26784\n",
      "4400 out of 26784\n",
      "4500 out of 26784\n",
      "4600 out of 26784\n",
      "4700 out of 26784\n",
      "4800 out of 26784\n",
      "4900 out of 26784\n",
      "5000 out of 26784\n",
      "5100 out of 26784\n",
      "5200 out of 26784\n",
      "5300 out of 26784\n",
      "5400 out of 26784\n",
      "5500 out of 26784\n",
      "5600 out of 26784\n",
      "5700 out of 26784\n",
      "5800 out of 26784\n",
      "5900 out of 26784\n",
      "6000 out of 26784\n",
      "6100 out of 26784\n",
      "6200 out of 26784\n",
      "6300 out of 26784\n",
      "6400 out of 26784\n",
      "6500 out of 26784\n",
      "6600 out of 26784\n",
      "6700 out of 26784\n",
      "6800 out of 26784\n",
      "6900 out of 26784\n",
      "7000 out of 26784\n",
      "7100 out of 26784\n",
      "7200 out of 26784\n",
      "7300 out of 26784\n",
      "7400 out of 26784\n",
      "7500 out of 26784\n",
      "7600 out of 26784\n",
      "7700 out of 26784\n",
      "7800 out of 26784\n",
      "7900 out of 26784\n",
      "8000 out of 26784\n",
      "8100 out of 26784\n",
      "8200 out of 26784\n",
      "8300 out of 26784\n",
      "8400 out of 26784\n",
      "8500 out of 26784\n",
      "8600 out of 26784\n",
      "8700 out of 26784\n",
      "8800 out of 26784\n",
      "8900 out of 26784\n",
      "9000 out of 26784\n",
      "9100 out of 26784\n",
      "9200 out of 26784\n",
      "9300 out of 26784\n",
      "9400 out of 26784\n",
      "9500 out of 26784\n",
      "9600 out of 26784\n",
      "9700 out of 26784\n",
      "9800 out of 26784\n",
      "9900 out of 26784\n",
      "10000 out of 26784\n",
      "10100 out of 26784\n",
      "10200 out of 26784\n",
      "10300 out of 26784\n",
      "10400 out of 26784\n",
      "10500 out of 26784\n",
      "10600 out of 26784\n",
      "10700 out of 26784\n",
      "10800 out of 26784\n",
      "10900 out of 26784\n",
      "11000 out of 26784\n",
      "11100 out of 26784\n",
      "11200 out of 26784\n",
      "11300 out of 26784\n",
      "11400 out of 26784\n",
      "11500 out of 26784\n",
      "11600 out of 26784\n",
      "11700 out of 26784\n",
      "11800 out of 26784\n",
      "11900 out of 26784\n",
      "12000 out of 26784\n",
      "12100 out of 26784\n",
      "12200 out of 26784\n",
      "12300 out of 26784\n",
      "12400 out of 26784\n",
      "12500 out of 26784\n",
      "12600 out of 26784\n",
      "12700 out of 26784\n",
      "12800 out of 26784\n",
      "12900 out of 26784\n",
      "13000 out of 26784\n",
      "13100 out of 26784\n",
      "13200 out of 26784\n",
      "13300 out of 26784\n",
      "13400 out of 26784\n",
      "13500 out of 26784\n",
      "13600 out of 26784\n",
      "13700 out of 26784\n",
      "13800 out of 26784\n",
      "13900 out of 26784\n",
      "14000 out of 26784\n",
      "14100 out of 26784\n",
      "14200 out of 26784\n",
      "14300 out of 26784\n",
      "14400 out of 26784\n",
      "14500 out of 26784\n",
      "14600 out of 26784\n",
      "14700 out of 26784\n",
      "14800 out of 26784\n",
      "14900 out of 26784\n",
      "15000 out of 26784\n",
      "15100 out of 26784\n",
      "15200 out of 26784\n",
      "15300 out of 26784\n",
      "15400 out of 26784\n",
      "15500 out of 26784\n",
      "15600 out of 26784\n",
      "15700 out of 26784\n",
      "15800 out of 26784\n",
      "15900 out of 26784\n",
      "16000 out of 26784\n",
      "16100 out of 26784\n",
      "16200 out of 26784\n",
      "16300 out of 26784\n",
      "16400 out of 26784\n",
      "16500 out of 26784\n",
      "16600 out of 26784\n",
      "16700 out of 26784\n",
      "16800 out of 26784\n",
      "16900 out of 26784\n",
      "17000 out of 26784\n",
      "17100 out of 26784\n",
      "17200 out of 26784\n",
      "17300 out of 26784\n",
      "17400 out of 26784\n",
      "17500 out of 26784\n",
      "17600 out of 26784\n",
      "17700 out of 26784\n",
      "17800 out of 26784\n",
      "17900 out of 26784\n",
      "18000 out of 26784\n",
      "18100 out of 26784\n",
      "18200 out of 26784\n",
      "18300 out of 26784\n",
      "18400 out of 26784\n",
      "18500 out of 26784\n",
      "18600 out of 26784\n",
      "18700 out of 26784\n",
      "18800 out of 26784\n",
      "18900 out of 26784\n",
      "19000 out of 26784\n",
      "19100 out of 26784\n",
      "19200 out of 26784\n",
      "19300 out of 26784\n",
      "19400 out of 26784\n",
      "19500 out of 26784\n",
      "19600 out of 26784\n",
      "19700 out of 26784\n",
      "19800 out of 26784\n",
      "19900 out of 26784\n",
      "20000 out of 26784\n",
      "20100 out of 26784\n",
      "20200 out of 26784\n",
      "20300 out of 26784\n",
      "20400 out of 26784\n",
      "20500 out of 26784\n",
      "20600 out of 26784\n",
      "20700 out of 26784\n",
      "20800 out of 26784\n",
      "20900 out of 26784\n",
      "21000 out of 26784\n",
      "21100 out of 26784\n",
      "21200 out of 26784\n",
      "21300 out of 26784\n",
      "21400 out of 26784\n",
      "21500 out of 26784\n",
      "21600 out of 26784\n",
      "21700 out of 26784\n",
      "21800 out of 26784\n",
      "21900 out of 26784\n",
      "22000 out of 26784\n",
      "22100 out of 26784\n",
      "22200 out of 26784\n",
      "22300 out of 26784\n",
      "22400 out of 26784\n",
      "22500 out of 26784\n",
      "22600 out of 26784\n",
      "22700 out of 26784\n",
      "22800 out of 26784\n",
      "22900 out of 26784\n",
      "23000 out of 26784\n",
      "23100 out of 26784\n",
      "23200 out of 26784\n",
      "23300 out of 26784\n",
      "23400 out of 26784\n",
      "23500 out of 26784\n",
      "23600 out of 26784\n",
      "23700 out of 26784\n",
      "23800 out of 26784\n",
      "23900 out of 26784\n",
      "24000 out of 26784\n",
      "24100 out of 26784\n",
      "24200 out of 26784\n",
      "24300 out of 26784\n",
      "24400 out of 26784\n",
      "24500 out of 26784\n",
      "24600 out of 26784\n",
      "24700 out of 26784\n",
      "24800 out of 26784\n",
      "24900 out of 26784\n",
      "25000 out of 26784\n",
      "25100 out of 26784\n",
      "25200 out of 26784\n",
      "25300 out of 26784\n",
      "25400 out of 26784\n",
      "25500 out of 26784\n",
      "25600 out of 26784\n",
      "25700 out of 26784\n",
      "25800 out of 26784\n",
      "25900 out of 26784\n",
      "26000 out of 26784\n",
      "26100 out of 26784\n",
      "26200 out of 26784\n",
      "26300 out of 26784\n",
      "26400 out of 26784\n",
      "26500 out of 26784\n",
      "26600 out of 26784\n",
      "26700 out of 26784\n",
      "(26784, 1158) len mm,sn: 1158 26784\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>(h. c.) andersensvej</th>\n",
       "      <th>a. f. beyersvej</th>\n",
       "      <th>a. n. hansens allé</th>\n",
       "      <th>aadum</th>\n",
       "      <th>aagade</th>\n",
       "      <th>aalborg frue landsogn</th>\n",
       "      <th>aalborggade</th>\n",
       "      <th>aalekistevej</th>\n",
       "      <th>aarhus havn skibe i havnen</th>\n",
       "      <th>...</th>\n",
       "      <th>øster bølle</th>\n",
       "      <th>øster farimagsgade</th>\n",
       "      <th>øster kvarter</th>\n",
       "      <th>øster søgade</th>\n",
       "      <th>øster voldgade</th>\n",
       "      <th>østerbrogade</th>\n",
       "      <th>østergade</th>\n",
       "      <th>østersøgade</th>\n",
       "      <th>østervoldgade</th>\n",
       "      <th>østre møllesti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kronborg</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>præstø</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bornholms</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.48</td>\n",
       "      <td>...</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svendborg</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ålborg</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                (h. c.) andersensvej  a. f. beyersvej  a. n. hansens allé  \\\n",
       "kronborg   0.0                  0.00             0.46                0.39   \n",
       "præstø     0.0                  0.00             0.00                0.00   \n",
       "bornholms  0.0                  0.39             0.39                0.50   \n",
       "svendborg  0.0                  0.00             0.45                0.39   \n",
       "ålborg     0.0                  0.00             0.00                0.00   \n",
       "\n",
       "           aadum  aagade  aalborg frue landsogn  aalborggade  aalekistevej  \\\n",
       "kronborg    0.00    0.00                   0.49         0.54          0.40   \n",
       "præstø      0.00    0.00                   0.00         0.00          0.50   \n",
       "bornholms   0.00    0.00                   0.38         0.44          0.46   \n",
       "svendborg   0.44    0.35                   0.54         0.60          0.40   \n",
       "ålborg      0.00    0.44                   0.69         0.76          0.42   \n",
       "\n",
       "           aarhus havn skibe i havnen  ...  øster bølle  øster farimagsgade  \\\n",
       "kronborg                         0.39  ...         0.48                0.45   \n",
       "præstø                           0.47  ...         0.59                0.44   \n",
       "bornholms                        0.48  ...         0.47                0.44   \n",
       "svendborg                        0.00  ...         0.52                0.56   \n",
       "ålborg                           0.40  ...         0.42                0.41   \n",
       "\n",
       "           øster kvarter  øster søgade  øster voldgade  østerbrogade  \\\n",
       "kronborg            0.47          0.47            0.53          0.61   \n",
       "præstø              0.47          0.58            0.46          0.47   \n",
       "bornholms           0.40          0.46            0.52          0.46   \n",
       "svendborg           0.52          0.59            0.57          0.67   \n",
       "ålborg              0.41          0.50            0.41          0.47   \n",
       "\n",
       "           østergade  østersøgade  østervoldgade  østre møllesti  \n",
       "kronborg        0.49         0.48           0.54            0.40  \n",
       "præstø          0.50         0.59           0.47            0.57  \n",
       "bornholms       0.41         0.47           0.52            0.49  \n",
       "svendborg       0.64         0.60           0.68            0.40  \n",
       "ålborg          0.52         0.51           0.33            0.41  \n",
       "\n",
       "[5 rows x 1158 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the potential first matches\n",
    "\n",
    "mm = miss.Sogne_data.unique()\n",
    "#sn = dd_org.simplename.unique() # It's a smaller list, and the extended version adds \"meaningless info\": sogne, landsogn, etc. which may distract the algorithm\n",
    "sn = dd.simplename.unique() # this uses my extended version of digdag\n",
    "\n",
    "distance_jaro = np.zeros((len(sn),len(mm)))\n",
    "distance_leven = np.zeros((len(sn),len(mm)))\n",
    "\n",
    "for i in range(len(sn)):\n",
    "    if i%100 == 0: print(i, 'out of' , len(sn))\n",
    "        \n",
    "    for j in range(len(mm)): #The internal loop could be done using apply (it should be the longer one)\n",
    "        #If variable is none skip\n",
    "        if not mm[j]: continue\n",
    "        \n",
    "        #This matrix is not simetric because x and y axis are not the same!\n",
    "        try:\n",
    "            distance_jaro[i][j] = distance.get_jaro_distance(sn[i],mm[j])\n",
    "            distance_leven[i][j] = Levenshtein.distance(sn[i],mm[j])/(len(sn[i])+len(mm[j]))\n",
    "        except:\n",
    "            print('Could not make it',i,j)\n",
    "            print(sn[i],mm[j])\n",
    "        \n",
    "#Index is the reference names found in digdag the columns the original data\n",
    "distance_jaro = pd.DataFrame(data = distance_jaro, columns = mm, index = sn)\n",
    "distance_leven = pd.DataFrame(data = distance_leven, columns = mm, index = sn)\n",
    "print(distance_jaro.shape, 'len mm,sn:', len(mm), len(sn)) #(26428, 1237)\n",
    "distance_jaro.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the best match for each data_sogn with at least with a minimum value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>navn</th>\n",
       "      <th>simplename</th>\n",
       "      <th>art</th>\n",
       "      <th>enhedid</th>\n",
       "      <th>enhedtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fåborg Sogn</td>\n",
       "      <td>aalborg frue landsogn</td>\n",
       "      <td>sogn</td>\n",
       "      <td>113312</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ålborg Købstadskommune</td>\n",
       "      <td>aalborggade</td>\n",
       "      <td>købstad</td>\n",
       "      <td>120656</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Århus Købstad</td>\n",
       "      <td>aarhus mark</td>\n",
       "      <td>købstad</td>\n",
       "      <td>120696</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Århusgård Amt</td>\n",
       "      <td>aarhusgade</td>\n",
       "      <td>amt</td>\n",
       "      <td>118831</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abildgård Sogn</td>\n",
       "      <td>abildgaardsgade</td>\n",
       "      <td>sogn</td>\n",
       "      <td>113934</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     navn             simplename      art enhedid enhedtype\n",
       "0             Fåborg Sogn  aalborg frue landsogn     sogn  113312       NaN\n",
       "1  Ålborg Købstadskommune            aalborggade  købstad  120656       NaN\n",
       "2           Århus Købstad            aarhus mark  købstad  120696       NaN\n",
       "3           Århusgård Amt             aarhusgade      amt  118831       NaN\n",
       "4          Abildgård Sogn        abildgaardsgade     sogn  113934       NaN"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESHOLD = 0.9\n",
    "\n",
    "#Getting the highest match for each Sogne and filtering threshold\n",
    "a = distance_jaro.idxmax().reset_index(name = 'potential_match')\n",
    "b = distance_jaro.max().reset_index(name='jaro')\n",
    "dfmap = a.merge(b, on='index').rename(columns={'index':'data_name'})\n",
    "dfmap.to_csv(_path+'../out/mapping.tsv', sep='\\t', index=False)\n",
    "dfmap = dfmap[dfmap.jaro.astype(float) >= THRESHOLD]\n",
    "dfmap.head()\n",
    "\n",
    "#Getting the mapped info into DigDag v2 (not really the v2)\n",
    "dd2 = dfmap.merge(dd[['navn','simplename', 'art', 'enhedid']].sort_values('art', ascending=False).drop_duplicates('simplename', keep='first'), left_on='potential_match', right_on='simplename')\n",
    "dd2['simplename'] = dd2['data_name']\n",
    "dd2 = dd2[['navn','enhedid','art','simplename']]\n",
    "dd2 = pd.concat([dd2[['navn','simplename', 'art', 'enhedid']], dd], sort=False) #putting together\n",
    "dd2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1835\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>navn</th>\n",
       "      <th>enhedid</th>\n",
       "      <th>art</th>\n",
       "      <th>1845</th>\n",
       "      <th>1850</th>\n",
       "      <th>1860</th>\n",
       "      <th>1880</th>\n",
       "      <th>1885</th>\n",
       "      <th>1901</th>\n",
       "      <th>extended_digdag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aabenraa Sogn</td>\n",
       "      <td>113932</td>\n",
       "      <td>sogn</td>\n",
       "      <td>444</td>\n",
       "      <td>0</td>\n",
       "      <td>650</td>\n",
       "      <td>1404</td>\n",
       "      <td>1314</td>\n",
       "      <td>1044</td>\n",
       "      <td>{aabenraa, aabenraa landsogn}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aaker Sogn</td>\n",
       "      <td>115247</td>\n",
       "      <td>sogn</td>\n",
       "      <td>1864</td>\n",
       "      <td>1956</td>\n",
       "      <td>1978</td>\n",
       "      <td>2485</td>\n",
       "      <td>0</td>\n",
       "      <td>2421</td>\n",
       "      <td>{aaker}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aal Sogn</td>\n",
       "      <td>115248</td>\n",
       "      <td>sogn</td>\n",
       "      <td>917</td>\n",
       "      <td>972</td>\n",
       "      <td>962</td>\n",
       "      <td>1097</td>\n",
       "      <td>0</td>\n",
       "      <td>1299</td>\n",
       "      <td>{aal}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aarestrup Sogn</td>\n",
       "      <td>115255</td>\n",
       "      <td>sogn</td>\n",
       "      <td>468</td>\n",
       "      <td>523</td>\n",
       "      <td>611</td>\n",
       "      <td>773</td>\n",
       "      <td>0</td>\n",
       "      <td>844</td>\n",
       "      <td>{aarestrup}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abild Sogn</td>\n",
       "      <td>113795</td>\n",
       "      <td>sogn</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{abild}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             navn enhedid   art  1845  1850  1860  1880  1885  1901  \\\n",
       "0   Aabenraa Sogn  113932  sogn   444     0   650  1404  1314  1044   \n",
       "1      Aaker Sogn  115247  sogn  1864  1956  1978  2485     0  2421   \n",
       "2        Aal Sogn  115248  sogn   917   972   962  1097     0  1299   \n",
       "3  Aarestrup Sogn  115255  sogn   468   523   611   773     0   844   \n",
       "4      Abild Sogn  113795  sogn    90     0  1165     0     0     0   \n",
       "\n",
       "                 extended_digdag  \n",
       "0  {aabenraa, aabenraa landsogn}  \n",
       "1                        {aaker}  \n",
       "2                          {aal}  \n",
       "3                    {aarestrup}  \n",
       "4                        {abild}  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Starting again with the merges\n",
    "out = out_list.merge(dd2, left_on='Sogne_data', right_on='simplename', how='left')\n",
    "\n",
    "#Those are the missmatch\n",
    "miss = out[out.enhedid.isna()]\n",
    "miss.head()\n",
    "\n",
    "#Here are the match\n",
    "match = out[~out.enhedid.isna()]\n",
    "match.head()\n",
    "\n",
    "# Aggregating the match by enhedid and year\n",
    "agg_counts = match.groupby(['navn', 'enhedid', 'art'],as_index = False).agg({'1845':'sum', '1850':'sum','1860':'sum', '1880':'sum','1885':'sum', '1901':'sum'})\n",
    "\n",
    "# Grouping all enhedid to see how many different versions of the same Sogne we have in the data\n",
    "diff_counts = match.groupby(['navn','enhedid'])['Sogne_data'].apply(set).reset_index(name='extended_digdag') #if parenthesis is confusing add **.apply(lambda x: ', '.join(x))** before the reset index\n",
    "\n",
    "# Joining DFs and saving\n",
    "s = agg_counts.merge(diff_counts, on = ['navn','enhedid'])\n",
    "s.to_csv(_path+'../out/places_FT_jaro0.9_01.tsv', sep='\\t', index=False)\n",
    "print(len(s))\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting counts for other possible matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>potential_match</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>kronborg</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>præstø</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>bornholms</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>svendborg</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ålborg</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(h. c.) andersensvej</td>\n",
       "      <td>branderslevsogn</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(h. c.) andersensvej</td>\n",
       "      <td>gammel haderslev sogn</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(h. c.) andersensvej</td>\n",
       "      <td>broenderslev sogn</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(h. c.) andersensvej</td>\n",
       "      <td>store arden sogn</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(h. c.) andersensvej</td>\n",
       "      <td>gammel haderslev bysogn</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a. f. beyersvej</td>\n",
       "      <td>faarevejlebysogn</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>a. f. beyersvej</td>\n",
       "      <td>faarevejle bysogn</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>a. f. beyersvej</td>\n",
       "      <td>frederiksvaerk</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a. f. beyersvej</td>\n",
       "      <td>als soender herred</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a. f. beyersvej</td>\n",
       "      <td>avedøre bysogn</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                original          potential_match  score\n",
       "0                    NaN                 kronborg   0.00\n",
       "1                    NaN                   præstø   0.00\n",
       "2                    NaN                bornholms   0.00\n",
       "3                    NaN                svendborg   0.00\n",
       "4                    NaN                   ålborg   0.00\n",
       "5   (h. c.) andersensvej          branderslevsogn   0.69\n",
       "6   (h. c.) andersensvej    gammel haderslev sogn   0.68\n",
       "7   (h. c.) andersensvej        broenderslev sogn   0.67\n",
       "8   (h. c.) andersensvej         store arden sogn   0.66\n",
       "9   (h. c.) andersensvej  gammel haderslev bysogn   0.66\n",
       "10       a. f. beyersvej         faarevejlebysogn   0.69\n",
       "11       a. f. beyersvej        faarevejle bysogn   0.67\n",
       "12       a. f. beyersvej           frederiksvaerk   0.66\n",
       "13       a. f. beyersvej       als soender herred   0.66\n",
       "14       a. f. beyersvej           avedøre bysogn   0.66"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best possible matches\n",
    "\n",
    "concatenate = []\n",
    "i=0\n",
    "for col in distance_jaro.columns:\n",
    "    i = i+1\n",
    "    if i % 100 == 0: print(i, 'out of', len(distance_jaro.columns))\n",
    "    aux = distance_jaro.nlargest(5, col)[[col]]\n",
    "    aux.columns = ['score']\n",
    "    aux['original'] = col\n",
    "    concatenate.append(aux)\n",
    "\n",
    "concatenate = pd.concat(concatenate, sort=False)\n",
    "concatenate = concatenate.reset_index()\n",
    "concatenate.columns = ['potential_match','score','original']\n",
    "concatenate[['original','potential_match','score']][~concatenate.original.isin(concatenate[(concatenate.score >= 0.9) & ~concatenate.original.isna()].original.unique())].to_csv(_path+'../out/places_possible_matches_jaro_01.tsv', index=False, sep='\\t')\n",
    "\n",
    "concatenate = pd.read_csv(_path+'../out/places_possible_matches_jaro_01.tsv',  sep='\\t')\n",
    "concatenate.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4460 31510\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art</th>\n",
       "      <th>enhedid</th>\n",
       "      <th>enhedtype</th>\n",
       "      <th>navn</th>\n",
       "      <th>original</th>\n",
       "      <th>potential_match</th>\n",
       "      <th>score</th>\n",
       "      <th>simplename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sogn</td>\n",
       "      <td>113312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fåborg Sogn</td>\n",
       "      <td>aalborg frue landsogn</td>\n",
       "      <td>aalborg frue landsogn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>aalborg frue landsogn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>sogn</td>\n",
       "      <td>114286</td>\n",
       "      <td>76</td>\n",
       "      <td>Måløv Sogn</td>\n",
       "      <td>måloev landsogn</td>\n",
       "      <td>måloev landsogn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>måloev landsogn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>sogn</td>\n",
       "      <td>114589</td>\n",
       "      <td>76</td>\n",
       "      <td>Sjælør Sogn</td>\n",
       "      <td>sjæloer landsogn</td>\n",
       "      <td>sjæloer landsogn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sjæloer landsogn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>sogn</td>\n",
       "      <td>114282</td>\n",
       "      <td>76</td>\n",
       "      <td>Mørke Sogn</td>\n",
       "      <td>moerke landsogn</td>\n",
       "      <td>moerke landsogn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>moerke landsogn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>sogn</td>\n",
       "      <td>114277</td>\n",
       "      <td>76</td>\n",
       "      <td>Møborg Sogn</td>\n",
       "      <td>moeborg landsogn</td>\n",
       "      <td>moeborg landsogn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>moeborg landsogn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      art enhedid enhedtype         navn               original  \\\n",
       "0    sogn  113312       NaN  Fåborg Sogn  aalborg frue landsogn   \n",
       "183  sogn  114286        76   Måløv Sogn        måloev landsogn   \n",
       "180  sogn  114589        76  Sjælør Sogn       sjæloer landsogn   \n",
       "179  sogn  114282        76   Mørke Sogn        moerke landsogn   \n",
       "175  sogn  114277        76  Møborg Sogn       moeborg landsogn   \n",
       "\n",
       "           potential_match  score             simplename  \n",
       "0    aalborg frue landsogn    1.0  aalborg frue landsogn  \n",
       "183        måloev landsogn    1.0        måloev landsogn  \n",
       "180       sjæloer landsogn    1.0       sjæloer landsogn  \n",
       "179        moerke landsogn    1.0        moerke landsogn  \n",
       "175       moeborg landsogn    1.0       moeborg landsogn  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the digDag info for the matches but also for the non matches\n",
    "\n",
    "m = concatenate.merge(dd2[['navn','simplename', 'art', 'enhedid']].sort_values('art', ascending=False).drop_duplicates('simplename',keep='first'), left_on='potential_match', right_on='simplename', how='inner')\n",
    "m = m[['original','potential_match','score','navn','art','enhedid', 'simplename']]\n",
    "\n",
    "w = dd2.sort_values('art', ascending=False).drop_duplicates('simplename',keep='first')\n",
    "w['potential_match'] = w['simplename']\n",
    "w['original'] = w['simplename']\n",
    "w['score'] = 1\n",
    "\n",
    "m = pd.concat([w, m], sort=True)\n",
    "\n",
    "\n",
    "#Putting the things into place\n",
    "m['original'] = np.where(m.original.isna(), m['simplename'], m['original'])\n",
    "\n",
    "print(len(concatenate), len(m))\n",
    "m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Getting the counts for the original plus the counts for the potential matches in DigDag\n",
    "#Warning: Potential matches may not exist in the data...\n",
    "out = m.merge(out_list, left_on='original', right_on='Sogne_data', how='left').merge(out_list, left_on='potential_match', right_on='Sogne_data', how='left').fillna(0)\n",
    "for y in ['1845', '1850', '1860', '1880', '1885', '1901']:\n",
    "    out[y] = out[y+'_x'] + out[y+'_y']\n",
    "out = out[['original', 'potential_match', 'score', 'navn', 'art', 'enhedid', '1845', '1850', '1860', '1880', '1885', '1901']].sort_values('original')\n",
    "out.to_csv(_path+'../out/places_possible_matches_jaro_01.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! :D\n"
     ]
    }
   ],
   "source": [
    "print('Done! :D')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
